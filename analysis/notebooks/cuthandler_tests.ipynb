{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\n",
    "import os\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import copy\n",
    "from particle import Particle\n",
    "import matplotlib.pyplot as plt\n",
    "from python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\n",
    "from apps import photon_pairs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_conf = Plots.PlotConfig()\n",
    "plt_conf.SHOW_PLOT = True\n",
    "plt_conf.SAVE_FOLDER = None\n",
    "# plt_conf.BINS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a_ = 1\n",
    "_b_ = 2\n",
    "x = 4\n",
    "\n",
    "eval(\"(x>_a_)|(x<_b_)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"np.\" + repr(np.array([1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dumb_sum(num):\n",
    "    def next_val(index):\n",
    "        if index >= num:\n",
    "            return index\n",
    "        else:\n",
    "            return index + next_val(index+1)\n",
    "    return next_val(0)\n",
    "\n",
    "dumb_sum(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_values_to_func_str(func_str, values):\n",
    "    for i in range(len(values)):\n",
    "        func_str = func_str.replace(f\"_{i}_\", f\"{values[i]}\")\n",
    "    return func_str\n",
    "\n",
    "def cuts_to_func(values, *operations, func_str=None):\n",
    "    ops = {\n",
    "        \"==\": operator.eq,\n",
    "        \"!=\": operator.ne,\n",
    "        \"<\": operator.lt,\n",
    "        \"<=\": operator.le,\n",
    "        \">\": operator.gt,\n",
    "        \">=\": operator.ge}\n",
    "\n",
    "    if func_str is None:\n",
    "        if len(operations) != 1:\n",
    "            raise ValueError(\"operations must be sepcified if func_str is not specified\")\n",
    "        else:\n",
    "            operations = operations[0]\n",
    "        def cut_func(property_to_cut):\n",
    "            def next_cut(index):\n",
    "                curr_cut = ops[operations[index]](property_to_cut, values[index])\n",
    "                if index <= 0:\n",
    "                    return curr_cut\n",
    "                else:\n",
    "                    return np.logical_and(curr_cut, next_cut(index-1))\n",
    "            return next_cut(len(values)-1)\n",
    "        return cut_func\n",
    "    else:\n",
    "        formatted_func = insert_values_to_func_str(func_str, values)\n",
    "        return lambda x: eval(formatted_func)\n",
    "\n",
    "def cuts_to_str(values, *operations, func_str=None, name_format=False):\n",
    "    str_ini = \", \" if name_format else \"\"\n",
    "    if func_str is None:\n",
    "        if len(operations) != 1:\n",
    "            raise ValueError(\"operations must be sepcified if func_str is not specified\")\n",
    "        else:\n",
    "            operations = operations[0]\n",
    "        \n",
    "        if len(values) == 1:\n",
    "            str_ini = \"\" if name_format else \"x\"\n",
    "            return str_ini + f\" {operations[0]} {values[0]}\"\n",
    "        elif len(values) == 2:\n",
    "            if (\">\" in operations[0]) and (\"<\" in operations[1]):\n",
    "                return str_ini + f\"{values[0]} {operations[0].replace('>','<')} x {operations[1]} {values[1]}\"\n",
    "            elif (\">\" in operations[1]) and (\"<\" in operations[0]):\n",
    "                return str_ini + f\"{values[1]} {operations[1].replace('>','<')} x {operations[0]} {values[0]}\"\n",
    "        return str_ini + \" and \".join([f\"(x {op} {val})\" for val, op in zip(values, operations)])\n",
    "\n",
    "    else:\n",
    "        return str_ini + insert_values_to_func_str(func_str, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x==values[0] | x>_b_'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"x==_a_ | x>_b_\".replace(f\"_{chr(ord('a') + 0)}_\", f\"values[{0}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(x==2) or (x>5)\n",
      ", (x==2) or (x>5)\n"
     ]
    }
   ],
   "source": [
    "print(cuts_to_func([2,5], func_str=\"(x==_0_) or (x>_1_)\")(5))\n",
    "print(cuts_to_str([2,5], func_str=\"(x==_0_) or (x>_1_)\"))\n",
    "print(cuts_to_str([2,5], func_str=\"(x==_0_) or (x>_1_)\", name_format=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "2 <= x < 5\n",
      ", 2 <= x < 5\n"
     ]
    }
   ],
   "source": [
    "print(cuts_to_func([2,5], [\">=\", \"<\"])(5))\n",
    "print(cuts_to_str([2,5], [\">=\", \"<\"]))\n",
    "print(cuts_to_str([2,5], [\">=\", \"<\"], name_format=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(x == 5) and (x > 10)\n",
      ", (x == 5) and (x > 10)\n"
     ]
    }
   ],
   "source": [
    "print(cuts_to_func([5,10], [\"==\", \">\"])(1))\n",
    "print(cuts_to_str([5,10], [\"==\", \">\"]))\n",
    "print(cuts_to_str([5,10], [\"==\", \">\"], name_format=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "x <= 10\n",
      " <= 10\n"
     ]
    }
   ],
   "source": [
    "print(cuts_to_func([10], [\"<=\"])(1))\n",
    "print(cuts_to_str([10], [\"<=\"]))\n",
    "print(cuts_to_str([10], [\"<=\"], name_format=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_to_func(cut):\n",
    "    if isinstance(cut, tuple):\n",
    "        if len(cut) == 1:\n",
    "            return lambda count: count >= cut[0]\n",
    "        elif len(cut) == 2:\n",
    "            return lambda count: np.logical_and(\n",
    "                count >= min(cut), count <= max(cut))\n",
    "        else:\n",
    "            raise ValueError(f\"Cut tuple {cut} must contain 1 or 2 values.\")\n",
    "    if isinstance(cut, list):\n",
    "        if len(cut) == 1:\n",
    "            return lambda count: count > cut[0]\n",
    "        elif len(cut) == 2:\n",
    "            return lambda count: np.logical_and(\n",
    "                count > min(cut), count < max(cut))\n",
    "        else:\n",
    "            raise ValueError(f\"Cut list {cut} must contain 1 or 2 values.\")\n",
    "    elif cut is None:\n",
    "        return lambda count: True\n",
    "    else:\n",
    "        return lambda count: count == cut\n",
    "    \n",
    "def cut_to_str(cut):\n",
    "    if isinstance(cut, tuple):\n",
    "        if len(cut) == 1:\n",
    "            return f\" >= {cut[0]}\"\n",
    "        elif len(cut) == 2:\n",
    "            return f\", {min(cut)} <= X <= {max(cut)}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Cut tuple {cut} must contain 1 or 2 values.\")\n",
    "    if isinstance(cut, list):\n",
    "        if len(cut) == 1:\n",
    "            return f\" > {cut[0]}\"\n",
    "        elif len(cut) == 2:\n",
    "            return f\", {min(cut)} < X < {max(cut)}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Cut list {cut} must contain 1 or 2 values.\")\n",
    "    elif cut is None:\n",
    "        return \", no cut\"\n",
    "    else:\n",
    "        return f\" == {cut}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to change! Need it to give the cumulative mask since the first mask\n",
    "\n",
    "class MaskIter():\n",
    "    def __init__(self, start_sigs, masks):\n",
    "        self.sigs = start_sigs\n",
    "        self.masks = masks\n",
    "        self.iter_max = len(masks)\n",
    "        self.index = 0\n",
    "        self.curr_mask = self.masks[self.index]\n",
    "\n",
    "        if self.iter_max != len(self.sigs):\n",
    "            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\n",
    "        if self.index >= self.iter_max:\n",
    "            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\n",
    "\n",
    "        self.mask_inds = list(range(self.iter_max))\n",
    "        self.simultaneous_masks = []\n",
    "        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\n",
    "        self.next_simul = simul_list[1:] + [False]\n",
    "        self.init_simul = []\n",
    "        last_simul = 0\n",
    "        for i, this_simul in enumerate(simul_list):\n",
    "            if not this_simul:\n",
    "                last_simul = i\n",
    "            self.init_simul.append(last_simul)\n",
    "        return\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        self.curr_mask = self.masks[0]\n",
    "        return self\n",
    "\n",
    "    def check_simul_masks(self, sig1, sig2):\n",
    "        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\n",
    "\n",
    "    def get_mask_func(self, mask, next_simul):\n",
    "        if next_simul:\n",
    "            def apply_mask_func(data):\n",
    "                return mask, data\n",
    "        else:\n",
    "            def apply_mask_func(data):\n",
    "                return mask, data[mask]\n",
    "        return apply_mask_func\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.iter_max:\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.init_simul[self.index] == self.index:\n",
    "            self.curr_mask = self.masks[self.index]\n",
    "        else:\n",
    "            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\n",
    "        self.index += 1\n",
    "        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\n",
    "        \n",
    "    def __getitem__(self, sli : slice):\n",
    "        if (sli.step is not None) and (sli.step < 0):\n",
    "            rev_slice = slice(None, None, -1)\n",
    "            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\n",
    "        else:\n",
    "            rev_slice = slice(None, None, None)\n",
    "        this_index = self.mask_inds[sli]\n",
    "        init_masks = self.init_simul[sli]\n",
    "        next_simuls = self.next_simul[sli]\n",
    "        res = []\n",
    "        last_end = init_masks[0]\n",
    "        curr_mask = self.masks[last_end]\n",
    "        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\n",
    "            if init_i > last_end:\n",
    "                last_end = init_i\n",
    "                curr_mask = self.masks[last_end]\n",
    "            for new_mask in self.masks[last_end+1:this_i+1]:\n",
    "                curr_mask = np.logical_and(curr_mask, new_mask)\n",
    "            res.append(self.get_mask_func(curr_mask, next_simul))\n",
    "        return res[rev_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutHandler():\n",
    "    _default_particles = [\n",
    "        211, -211, 13, -13,\n",
    "        11, -11, 22, 2212, 321]\n",
    "    _event_table_cols = np.array([\n",
    "            \"Remaining events\", \"Percentage of total events remaining\",\n",
    "            \"Relative percentage events\"])\n",
    "    _pfo_table_cols = np.array([\n",
    "            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\n",
    "            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\n",
    "    _particle_table_cols = [\n",
    "            \"remaining\", \"percentage remaining\",\n",
    "            \"relative percentage remaining\", \"average per event\"]\n",
    "\n",
    "    # @staticmethod\n",
    "    # def _init_doc(func):\n",
    "    #     documentation = \"\"\"\n",
    "    #     Create new a `CutHandler` object to store applied masks\n",
    "    #     and return a table of tracked particles when asked.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     evts : Master.Data, optional\n",
    "    #         Initial events the masks are being applied from.\n",
    "    #         If not set here, it must be set for getting a\n",
    "    #         table using `self.set_init_evts(evts)`. Default\n",
    "    #         is None.\n",
    "    #     particles_to_tag : list, optional\n",
    "    #         List of pdg codes to be tracked by the tables.\n",
    "    #         Default is\n",
    "    #     \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\n",
    "        \n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     CutHandler\n",
    "    #         New `CutHandler` instance.\n",
    "    #     \"\"\"\n",
    "    #     func.__doc__ = documentation\n",
    "    #     return func\n",
    "    # @_init_doc\n",
    "    def __init__(\n",
    "            self,\n",
    "            evts: Master.Data = None,\n",
    "            particles_to_tag: list = _default_particles):\n",
    "        \"\"\"\n",
    "        Create new a `CutHandler` object to store applied masks\n",
    "        and return a table of tracked particles when asked.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        evts : Master.Data, optional\n",
    "            Initial events the masks are being applied from.\n",
    "            If not set here, it must be set for getting a\n",
    "            table using `self.set_init_evts(evts)`. Default\n",
    "            is None.\n",
    "        particles_to_tag : list, optional\n",
    "            List of pdg codes to be tracked by the tables.\n",
    "            Default is [211, -211, 13, -13,11, -11, 22, 2212, 321]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        CutHandler\n",
    "            New `CutHandler` instance.\n",
    "        \"\"\"\n",
    "        self._masks = []\n",
    "        self._signatures = []\n",
    "        self._start_sig = ()\n",
    "        self._end_sig = ()\n",
    "        self.curr_mask_index = 0\n",
    "        self.concat_index = 0\n",
    "        self._concat_indicies = [0]\n",
    "        self._pfos_init = False\n",
    "        self._init_data = None\n",
    "        self._particle_tags = None\n",
    "        self._data_changed = True\n",
    "        self.init_events_set = False\n",
    "        if evts is not None:\n",
    "            self.set_init_evts(evts)\n",
    "        self._last_pfo_counts = None\n",
    "        self._names=[]\n",
    "\n",
    "        self._particles = particles_to_tag\n",
    "\n",
    "        self._table_data = {}\n",
    "        return\n",
    "\n",
    "    def _gen_basic_counts(self):\n",
    "        init_evt_count = ak.num(self._init_data, axis=0)\n",
    "        init_pfo_count = ak.count(self._init_data)\n",
    "        results = {\n",
    "            \"Name\":[\"Initial data\"],\n",
    "            \"Remaining events\":[init_evt_count],\n",
    "            \"Percentage of total events remaining\":[100.],\n",
    "            \"Relative percentage events\":[100.],\n",
    "            \"Remaining PFOs\":[init_pfo_count],\n",
    "            \"Percentage of total PFOs remaining\":[100.],\n",
    "            \"Relative percentage of PFOs\":[100.],\n",
    "            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\n",
    "        last_evt_count = init_evt_count\n",
    "        last_pfo_count = init_pfo_count\n",
    "        data = self._init_data\n",
    "        for name, application_func in zip(self._names, self):\n",
    "            this_mask, new_data = application_func(data)\n",
    "            this_evt_count = ak.num(data[this_mask], axis=0)\n",
    "            this_pfo_count = ak.count(data[this_mask])\n",
    "            results[\"Name\"].append(name)\n",
    "            results[\"Remaining events\"].append(this_evt_count)\n",
    "            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\n",
    "            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\n",
    "            results[\"Remaining PFOs\"].append(this_pfo_count)\n",
    "            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\n",
    "            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\n",
    "            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\n",
    "            last_evt_count = this_evt_count\n",
    "            last_pfo_count = this_pfo_count\n",
    "            data = new_data\n",
    "        return results\n",
    "\n",
    "    def _gen_particle_counts(self, init_list):\n",
    "        init_count = np.sum(init_list)\n",
    "        results = {\n",
    "            \"remaining\": [init_count],\n",
    "            \"percentage remaining\": [100.],\n",
    "            \"relative percentage remaining\": [100.],\n",
    "            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\n",
    "        data = init_list\n",
    "        for application_func in self:\n",
    "            this_mask, new_data = application_func(data)\n",
    "            particle_count = np.sum(data[this_mask])\n",
    "            results[\"remaining\"].append(particle_count)\n",
    "            results[\"percentage remaining\"].append(100. * particle_count/init_count)\n",
    "            results[\"relative percentage remaining\"].append(\n",
    "                100. * particle_count/results[\"remaining\"][-2])\n",
    "            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\n",
    "            data = new_data\n",
    "        return results\n",
    "\n",
    "    # def GeneratePi0Tags(self, evts : Master.Data):\n",
    "    #     photons_mask = evts.trueParticlesBT.pdg == 22\n",
    "    #     return Tags.GeneratePi0Tags(evts, photons_mask)\n",
    "\n",
    "    def set_init_evts(self, evts : Master.Data):\n",
    "        \"\"\"\n",
    "        Set the initial event counts to be cut using the masks.\n",
    "        This is automatically performed if as `Master.Data`\n",
    "        object is passed in initialisation.\n",
    "        \n",
    "        This must be performed prior to generating a table.\n",
    "\n",
    "        Use `self.init_data_set` for a boolean indicating if\n",
    "        the events have been set.\n",
    "\n",
    "        N.B. if we want to to this for truth, we must change evts\n",
    "        to be an acutal akward array (i.e.\n",
    "        `evts.recoParticles.number` for reco and\n",
    "        `evts.trueParticles.number` for truth). At the moment,\n",
    "        we take a Master.Data object an pull the\n",
    "        `evts.recoParticles.number` from it.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        evts : Master.Data\n",
    "            Initial events the masks are being applied from.\n",
    "        \"\"\"\n",
    "        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\n",
    "        self._init_data_sig = self._get_mask_signature(self._init_data)\n",
    "        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\n",
    "        self._data_changed = True\n",
    "        self.init_events_set = True\n",
    "        return\n",
    "\n",
    "    def _get_mask_signature(self, mask, end=False):\n",
    "        flat_array = isinstance(ak.count(mask, axis=0), int)\n",
    "        if not end:\n",
    "            pfo_level = -1 if flat_array else ak.count(mask)\n",
    "            start_sig = (ak.num(mask, axis=0), pfo_level)\n",
    "            return start_sig\n",
    "        if flat_array:\n",
    "            end_sig = (ak.sum(mask), -1)\n",
    "        else:\n",
    "            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\n",
    "        return end_sig\n",
    "    \n",
    "    def _validate_signature(self, signature, raise_exception=True):\n",
    "        if self._start_sig == ():\n",
    "            return\n",
    "        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\n",
    "        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\n",
    "        if (not good_mask) and raise_exception:\n",
    "            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\n",
    "                             + f\" the required signature of ({self._start_sig[0]} events, \"\n",
    "                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\n",
    "                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\n",
    "        return good_mask\n",
    "\n",
    "    def add_mask(self, mask: ak.Array, name: str):\n",
    "        \"\"\"\n",
    "        Add a mask to the instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mask : ak.Array\n",
    "            Boolean mask of the cut applied.\n",
    "        name : str\n",
    "            Name indicating what the cut did.\n",
    "        \"\"\"\n",
    "        this_sig = self._get_mask_signature(mask)\n",
    "        self._validate_signature(this_sig)\n",
    "        self._start_sig = this_sig\n",
    "        self._end_sig = self._get_mask_signature(mask, end=True)\n",
    "        self._masks.append(mask)\n",
    "        self._signatures.append(this_sig)\n",
    "        self._names.append(name)\n",
    "        self.curr_mask_index += 1\n",
    "        return\n",
    "\n",
    "    def _mask_appliers(self):\n",
    "        return MaskIter(self._signatures, self._masks)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self._mask_appliers()\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "    \n",
    "    def apply_masks(\n",
    "            self, data: ak.Array,\n",
    "            return_table: bool = False,\n",
    "            application_concat_index: int = 0,\n",
    "            application_true_index: int = None):\n",
    "        \"\"\"\n",
    "        Apply the masks in the instance to the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ak.Array\n",
    "            Data to which the masks are applied. Must\n",
    "            match the signature of the first mask.\n",
    "        return_table : bool, optional\n",
    "            If `True`, the both the filtered mask and\n",
    "            corresponding table will be returned. Default\n",
    "            is False.\n",
    "        application_concat_index : int, optional\n",
    "            Initial concatenation from which to apply masks.\n",
    "            If data has already been filtered, use this to\n",
    "            change from where the mask application begins.\n",
    "            Current concatenation index can be seen using\n",
    "            `self.concate_index`. Default is 0.\n",
    "        application_true_index : int, optional\n",
    "            Selects an arbitray mask as the starting point from\n",
    "            which to begin applying masks. This can be used\n",
    "            selections have not been grouped via concatenations.\n",
    "            Current mask index can be seen using\n",
    "            `self.curr_mask_index`. This will override\n",
    "            `initial_concat_index` if set. Default is None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ak.Array\n",
    "            Filtered data.\n",
    "        pd.DataFrame, optional\n",
    "            Cuts table, only returned if `return_table` is\n",
    "            True.\n",
    "        \"\"\"\n",
    "        # TODO exception throwing\n",
    "        if application_true_index is not None:\n",
    "            initial_index = application_true_index\n",
    "        else:\n",
    "            initial_index = self._concat_indicies[application_concat_index]\n",
    "        result = data\n",
    "        for application_func in self._mask_appliers()[initial_index:]:\n",
    "            _, result = application_func(result)\n",
    "        if return_table:\n",
    "            return result, self.get_table()\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    # def get_filters_list(self, application_concat_index=0):\n",
    "    #     new_data = data\n",
    "    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\n",
    "    #         mask, _ = application_func(result)\n",
    "        \n",
    "\n",
    "    def _gen_table(self):\n",
    "        if self._init_data is None:\n",
    "            raise Exception(\"Initial data not added, supply events using set_init_events.\")\n",
    "        if not self._data_changed:\n",
    "            return\n",
    "        self._table_data.update(self._gen_basic_counts())\n",
    "        for particle in self._particles:\n",
    "            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\n",
    "            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\n",
    "        self._data_changed = False\n",
    "        return\n",
    "\n",
    "        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\n",
    "        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\n",
    "    \n",
    "    def _gen_particle_cols_array(self, pdg):\n",
    "        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\n",
    "    def _gen_particle_cols_array_read(self, pdg, latex):\n",
    "        if latex:\n",
    "            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\n",
    "        else:\n",
    "            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\n",
    "\n",
    "    def _new_init_events(self, col, index, init_name):\n",
    "        if index == 0:\n",
    "            result = self._table_data[col]\n",
    "        else:\n",
    "            result = self._table_data[col][index:]\n",
    "            if \"percentage\" in col.lower():\n",
    "                if \"relative\" not in col.lower():\n",
    "                    init_percent = result[0]\n",
    "                    result = list(map(lambda p: p/init_percent, result))\n",
    "                else:\n",
    "                    result[0] = 100.\n",
    "        if col == \"Name\":\n",
    "            result[0] = init_name\n",
    "        return result\n",
    "\n",
    "    def get_table(\n",
    "            self, init_data_name: str = \"Initial data\",\n",
    "            initial_concat_index: int = 0,\n",
    "            initial_true_index: int = None,\n",
    "            latex: bool = False,\n",
    "            particles_list: list = _default_particles,\n",
    "            events: bool = True, pfos: bool = True,\n",
    "            counts: bool = True, percent_remain: bool = True,\n",
    "            relative_percent: bool = True, ave_per_event: bool = True):\n",
    "        \"\"\"\n",
    "        Generate the cuts table for the masks shown to the instance.\n",
    "\n",
    "        The initial events must have been set prior to calling this,\n",
    "        either in the initialisation, or the `set_init_events`\n",
    "        method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_data_name : str, optional\n",
    "            Name to be displayed for the pre-cuts row. Default is\n",
    "            `\"Initial data\"`\n",
    "        initial_concat_index : int, optional\n",
    "            Initial concatenation from which to generate the table\n",
    "            This can be used to i.e. removing initial event\n",
    "            selection cuts if they are not of interest. Current\n",
    "            concatenation index can be seen using\n",
    "            `self.concate_index`. Default is 0.\n",
    "        initial_true_index : int, optional\n",
    "            Selects an arbitray mask as the starting point from\n",
    "            which to generate the table. This can be used\n",
    "            selections have not been grouped via concatenations.\n",
    "            Current mask index can be seen using\n",
    "            `self.curr_mask_index`. This will override\n",
    "            `initial_concat_index` if set. Default is None.\n",
    "        latex : bool, optional\n",
    "            If `True`, result is a string which may be copied\n",
    "            directly into LaTeX. Default is False.\n",
    "        particles_list: list, optional\n",
    "            List of pdg codes of particles to be included in the\n",
    "            table. Default is [211, -211, 13, -13,11, -11, 22,\n",
    "            2212, 321]\n",
    "        events: bool, optional\n",
    "            If `True`, columns indicating the number of events\n",
    "            present are included. Default is True.\n",
    "        pfos: bool, optional\n",
    "            If `True`, columns indicating the total number of\n",
    "            PFOs present are included. Default is True.\n",
    "        counts: bool, optional\n",
    "            If `True`, columns indicating the number of\n",
    "            occurances for each tracked item are included.\n",
    "            Default is True.\n",
    "        percent_remain: bool, optional\n",
    "            If `True`, columns indicating the percentage of the\n",
    "            intial count for each tracked item are included.\n",
    "            Default is True.\n",
    "        relative_percent: bool, optional\n",
    "            If `True`, columns indicating the relative percentage\n",
    "            remaining compared to the previous row for each\n",
    "            tracked item are included. Default is True.\n",
    "        ave_per_event: bool, optional\n",
    "            If `True`, columns indicating the mean number of\n",
    "            occurances per event for each tracked item are\n",
    "            included. Not included for events data. Default is\n",
    "            True.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame or str\n",
    "            Table of results as a DataFrame if `latex` is False,\n",
    "            or a string if `latex` is True.\n",
    "        \"\"\"\n",
    "        self._gen_table()\n",
    "\n",
    "        if initial_concat_index > self.concat_index:\n",
    "            raise IndexError(\n",
    "                f\"Concatenation index {initial_concat_index} out of range, \"\n",
    "                + f\"only {self.concat_index} concatenation(s) present.\")\n",
    "        cols_to_use = [\"Name\"]\n",
    "        col_names = [\"Name\"]\n",
    "        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\n",
    "        if events:\n",
    "            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\n",
    "            cols_to_use += cols\n",
    "            col_names += cols\n",
    "        if pfos:\n",
    "            cols = self._pfo_table_cols[cols_to_keep].tolist()\n",
    "            cols_to_use += cols\n",
    "            col_names += cols\n",
    "        for p in particles_list:\n",
    "            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\n",
    "            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\n",
    "        \n",
    "        if initial_true_index is not None:\n",
    "            initial_index = initial_true_index\n",
    "        else:\n",
    "            initial_index = self._concat_indicies[initial_concat_index]\n",
    "        data = {}\n",
    "        for col, name in zip(cols_to_use, col_names):\n",
    "            data[name] = self._new_init_events(\n",
    "                col, initial_index, init_data_name)\n",
    "        if latex:\n",
    "            return pd.DataFrame(data).to_latex()\n",
    "        else:\n",
    "            return pd.DataFrame(data)\n",
    "\n",
    "    def concatenate(self, other, return_copy=False):\n",
    "        if not isinstance(other, CutHandler):\n",
    "            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\n",
    "        # Make sure the new set is consequtive\n",
    "        if not self._validate_signature(other._signatures[0], raise_exception=False):\n",
    "            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\n",
    "                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\n",
    "        if return_copy:\n",
    "            result = self.copy()\n",
    "        else:\n",
    "            result = self\n",
    "        result._masks = other._masks\n",
    "        result._signatures += other._signatures[1:]\n",
    "        result._start_sig = other._start_sig\n",
    "        result._end_sig = other._end_sig\n",
    "        result.concat_index += 1\n",
    "        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\n",
    "        if (result._init_data is None) and (other._init_data is not None):\n",
    "            result._init_data = other._init_data\n",
    "            result._init_data_sig = other._init_data_sig\n",
    "            result._data_changed = True\n",
    "            result.init_events_set = other.init_events_set\n",
    "            if result._particles != other._particles:\n",
    "                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\n",
    "            result._particle_tags = other._particle_tags\n",
    "        if return_copy:\n",
    "            return result\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self.concatenate(other, return_copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\n",
    "\n",
    "evts = Master.Data(file,\n",
    "                         nTuple_type=\"PDSPAnalyser\",\n",
    "                         nEvents=-1,\n",
    "                         start=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[0, 1, 2, 3, ... 671, 672, 673, 674]] type='23660 * var * int32'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts.recoParticles.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12267594\n",
      "23660\n"
     ]
    }
   ],
   "source": [
    "print(ak.count(evts.recoParticles.nHits > 80))\n",
    "print(ak.num(evts.recoParticles.nHits > 80, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U29')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(CutHandler._particle_table_cols).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'co_argcount',\n",
       " 'co_cellvars',\n",
       " 'co_code',\n",
       " 'co_consts',\n",
       " 'co_filename',\n",
       " 'co_firstlineno',\n",
       " 'co_flags',\n",
       " 'co_freevars',\n",
       " 'co_kwonlyargcount',\n",
       " 'co_lines',\n",
       " 'co_linetable',\n",
       " 'co_lnotab',\n",
       " 'co_name',\n",
       " 'co_names',\n",
       " 'co_nlocals',\n",
       " 'co_posonlyargcount',\n",
       " 'co_stacksize',\n",
       " 'co_varnames',\n",
       " 'replace']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(CutHandler.__init__.__code__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__annotations__: {}\n",
      "__builtins__: {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f9af5250760>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x7f9af5527370>, 'runfile': <function runfile at 0x7f9af53b5000>, '__IPYTHON__': True, 'display': <function display at 0x7f9af67103a0>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1014__': <capsule object NULL at 0x7f9ad5feb660>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1011__': <capsule object NULL at 0x7f9ab3460030>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9af5251e40>>}\n",
      "__call__: <method-wrapper '__call__' of function object at 0x7f9a52162e60>\n",
      "__class__: <class 'function'>\n",
      "__closure__: None\n",
      "__code__: <code object __init__ at 0x7f9a52742a20, file \"/tmp/ipykernel_4100665/3513821892.py\", line 42>\n",
      "__defaults__: (None, [211, -211, 13, -13, 11, -11, 22, 2212, 321])\n",
      "__delattr__: <method-wrapper '__delattr__' of function object at 0x7f9a52162e60>\n",
      "__dict__: {}\n",
      "__dir__: <built-in method __dir__ of function object at 0x7f9a52162e60>\n",
      "__doc__: Test\n",
      "__eq__: <method-wrapper '__eq__' of function object at 0x7f9a52162e60>\n",
      "__format__: <built-in method __format__ of function object at 0x7f9a52162e60>\n",
      "__ge__: <method-wrapper '__ge__' of function object at 0x7f9a52162e60>\n",
      "__get__: <method-wrapper '__get__' of function object at 0x7f9a52162e60>\n",
      "__getattribute__: <method-wrapper '__getattribute__' of function object at 0x7f9a52162e60>\n",
      "__globals__: {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'Particle.from_pdgid(211)', \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'Particle.from_pdgid(211)', 'dir(Particle.from_pdgid(211))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'cutter = CutHandler2(evts)', 'cutter = CutHandler(evts)', 'cutter.get_table()', 'print(cutter.get_table())', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._gen_particle_cols_array(211)', 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', 'CutHandler._particle_table_cols.dtype', 'np.array(CutHandler._particle_table_cols).dtype', 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._table_data', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter.get_table()', 'cutter.get_table(particles_list=[])', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], latex=True)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22], latex=True)', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], ave_per_event=False)', 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'Particles.from_pdgid(211)', 'Particle.from_pdgid(211)', 'f\"Particle.from_pdgid(211)\"', 'f\"{Particle.from_pdgid(211)}\"', '\"pi+\"', 'dir(Particle.from_pdgid(211))', 'dir(Particle.from_pdgid(211).C)', 'Particle.from_pdgid(211).C', 'dir(Particle.from_pdgid(211).C)', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).pdg_name', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).__str__', 'Particle.from_pdgid(211).__str__()', 'Particle.from_pdgid(211)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.set_init_evts.__doc__', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'dir(CutHandler.__init__)', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")'], '_oh': {4: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 5: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 12: Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], 18: array(<map object at 0x7f9a527c1600>, dtype=object), 19: array(<map object at 0x7f9a527c2c80>, dtype=object), 25: dtype('<U29'), 26: array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), 31: {}, 36:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], 37:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , 38:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 39:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , 43: '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', 44:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 45:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , 46:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , 47:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 51:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , 55:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 57: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 58: 'Particle.from_pdgid(211)', 59: 'pi+', 60: 'pi+', 61: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 62: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 63: <Parity.u: 5>, 64: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 65: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 66: 'pi', 67: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 68: <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, 69: 'pi+', 70: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 73: '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', 74: '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 76: '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 80: 'Test', 81: ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, '_dh': [PosixPath('/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks')], 'In': ['', 'Particle.from_pdgid(211)', \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'Particle.from_pdgid(211)', 'dir(Particle.from_pdgid(211))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'cutter = CutHandler2(evts)', 'cutter = CutHandler(evts)', 'cutter.get_table()', 'print(cutter.get_table())', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._gen_particle_cols_array(211)', 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', 'CutHandler._particle_table_cols.dtype', 'np.array(CutHandler._particle_table_cols).dtype', 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._table_data', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter.get_table()', 'cutter.get_table(particles_list=[])', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], latex=True)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22], latex=True)', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], ave_per_event=False)', 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'Particles.from_pdgid(211)', 'Particle.from_pdgid(211)', 'f\"Particle.from_pdgid(211)\"', 'f\"{Particle.from_pdgid(211)}\"', '\"pi+\"', 'dir(Particle.from_pdgid(211))', 'dir(Particle.from_pdgid(211).C)', 'Particle.from_pdgid(211).C', 'dir(Particle.from_pdgid(211).C)', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).pdg_name', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).__str__', 'Particle.from_pdgid(211).__str__()', 'Particle.from_pdgid(211)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.set_init_evts.__doc__', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'dir(CutHandler.__init__)', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")'], 'Out': {4: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 5: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 12: Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], 18: array(<map object at 0x7f9a527c1600>, dtype=object), 19: array(<map object at 0x7f9a527c2c80>, dtype=object), 25: dtype('<U29'), 26: array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), 31: {}, 36:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], 37:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , 38:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 39:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , 43: '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', 44:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 45:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , 46:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , 47:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 51:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , 55:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 57: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 58: 'Particle.from_pdgid(211)', 59: 'pi+', 60: 'pi+', 61: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 62: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 63: <Parity.u: 5>, 64: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 65: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 66: 'pi', 67: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 68: <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, 69: 'pi+', 70: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 73: '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', 74: '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 76: '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 80: 'Test', 81: ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9af5251e40>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f9af5252560>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f9af5252560>, '_': ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '__': 'Test', '___': '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 'os': <module 'os' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/os.py'>, 'sys': <module 'sys' (built-in)>, '__vsc_ipynb_file__': '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb', '_i': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', '_ii': 'dir(CutHandler.__init__)', '_iii': 'CutHandler.__init__.__doc__', '_i1': 'Particle.from_pdgid(211)', '_i2': \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'operator': <module 'operator' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/operator.py'>, 'np': <module 'numpy' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/numpy/__init__.py'>, 'ak': <module 'awkward' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/awkward/__init__.py'>, 'pd': <module 'pandas' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/__init__.py'>, 'copy': <module 'copy' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/copy.py'>, 'Particle': <class 'particle.particle.particle.Particle'>, 'plt': <module 'matplotlib.pyplot' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/matplotlib/pyplot.py'>, 'EventSelection': <module 'python.analysis.EventSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/EventSelection.py'>, 'Plots': <module 'python.analysis.Plots' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Plots.py'>, 'vector': <module 'python.analysis.vector' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/vector.py'>, 'PairSelection': <module 'python.analysis.PairSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/PairSelection.py'>, 'Master': <module 'python.analysis.Master' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Master.py'>, 'PFOSelection': <module 'python.analysis.PFOSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/PFOSelection.py'>, 'Tags': <module 'python.analysis.Tags' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Tags.py'>, 'photon_pairs': <module 'apps.photon_pairs' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/apps/photon_pairs.py'>, 'time': <module 'time' (built-in)>, '_i3': 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'plt_conf': <python.analysis.Plots.PlotConfig object at 0x7f9aec500790>, '_i4': 'Particle.from_pdgid(211)', '_4': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i5': 'dir(Particle.from_pdgid(211))', '_5': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i6': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'CutHandler': <class '__main__.CutHandler'>, '_i7': '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'MaskIter': <class '__main__.MaskIter'>, '_i8': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '_i9': 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'file': '/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root', 'evts': <python.analysis.Master.Data object at 0x7f9ab20780d0>, '_i10': 'cutter = CutHandler2(evts)', '_i11': 'cutter = CutHandler(evts)', 'cutter': <__main__.CutHandler object at 0x7f9a5276ce20>, '_i12': 'cutter.get_table()', '_12': Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], '_i13': 'print(cutter.get_table())', '_i14': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i15': 'cutter = CutHandler(evts)', '_i16': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i17': 'print(cutter.get_table())', '_i18': 'cutter._gen_particle_cols_array(211)', '_18': array(<map object at 0x7f9a527c1600>, dtype=object), '_i19': 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_19': array(<map object at 0x7f9a527c2c80>, dtype=object), '_i20': 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_i21': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_i22': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', '_i23': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', '_i24': 'CutHandler._particle_table_cols.dtype', '_i25': 'np.array(CutHandler._particle_table_cols).dtype', '_25': dtype('<U29'), '_i26': 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', '_26': array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), '_i27': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i28': 'cutter = CutHandler(evts)', '_i29': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i30': 'print(cutter.get_table())', '_i31': 'cutter._table_data', '_31': {}, '_i32': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i33': 'cutter = CutHandler(evts)', '_i34': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i35': 'print(cutter.get_table())', '_i36': 'cutter.get_table()', '_36':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], '_i37': 'cutter.get_table(particles_list=[])', '_37':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , '_i38': 'cutter.get_table(particles_list=[22])', '_38':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , '_i39': 'cutter.get_table(particles_list=[22], latex=True)', '_39':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , '_i40': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i41': 'cutter = CutHandler(evts)', '_i42': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i43': 'cutter.get_table(particles_list=[22], latex=True)', '_43': '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', '_i44': 'cutter.get_table(particles_list=[22])', '_44':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , '_i45': 'cutter.get_table(particles_list=[22], ave_per_event=False)', '_45':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , '_i46': 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', '_46':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , '_i47': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_47':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , '_i48': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i49': 'cutter = CutHandler(evts)', '_i50': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i51': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_51':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , '_i52': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i53': 'cutter = CutHandler(evts)', '_i54': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i55': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_55':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , '_i56': 'Particles.from_pdgid(211)', '_i57': 'Particle.from_pdgid(211)', '_57': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i58': 'f\"Particle.from_pdgid(211)\"', '_58': 'Particle.from_pdgid(211)', '_i59': 'f\"{Particle.from_pdgid(211)}\"', '_59': 'pi+', '_i60': '\"pi+\"', '_60': 'pi+', '_i61': 'dir(Particle.from_pdgid(211))', '_61': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i62': 'dir(Particle.from_pdgid(211).C)', '_62': ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], '_i63': 'Particle.from_pdgid(211).C', '_63': <Parity.u: 5>, '_i64': 'dir(Particle.from_pdgid(211).C)', '_64': ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], '_i65': 'dir(Particle.from_pdgid(211))', '_65': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i66': 'Particle.from_pdgid(211).pdg_name', '_66': 'pi', '_i67': 'dir(Particle.from_pdgid(211))', '_67': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i68': 'Particle.from_pdgid(211).__str__', '_68': <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, '_i69': 'Particle.from_pdgid(211).__str__()', '_69': 'pi+', '_i70': 'Particle.from_pdgid(211)', '_70': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i71': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i72': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i73': 'CutHandler.set_init_evts.__doc__', '_73': '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', '_i74': 'CutHandler.__init__.__doc__', '_74': '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', '_i75': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i76': 'CutHandler.__init__.__doc__', '_76': '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', '_i77': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i78': 'CutHandler.__init__.__doc__', '_i79': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i80': 'CutHandler.__init__.__doc__', '_80': 'Test', '_i81': 'dir(CutHandler.__init__)', '_81': ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '_i82': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', '_i83': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")', 'prop': '__globals__'}\n",
      "__gt__: <method-wrapper '__gt__' of function object at 0x7f9a52162e60>\n",
      "__hash__: <method-wrapper '__hash__' of function object at 0x7f9a52162e60>\n",
      "__init__: <method-wrapper '__init__' of function object at 0x7f9a52162e60>\n",
      "__init_subclass__: <built-in method __init_subclass__ of type object at 0x56479a10e3c0>\n",
      "__kwdefaults__: None\n",
      "__le__: <method-wrapper '__le__' of function object at 0x7f9a52162e60>\n",
      "__lt__: <method-wrapper '__lt__' of function object at 0x7f9a52162e60>\n",
      "__module__: __main__\n",
      "__name__: __init__\n",
      "__ne__: <method-wrapper '__ne__' of function object at 0x7f9a52162e60>\n",
      "__new__: <built-in method __new__ of type object at 0x56479a10e3c0>\n",
      "__qualname__: CutHandler.__init__\n",
      "__reduce__: <built-in method __reduce__ of function object at 0x7f9a52162e60>\n",
      "__reduce_ex__: <built-in method __reduce_ex__ of function object at 0x7f9a52162e60>\n",
      "__repr__: <method-wrapper '__repr__' of function object at 0x7f9a52162e60>\n",
      "__setattr__: <method-wrapper '__setattr__' of function object at 0x7f9a52162e60>\n",
      "__sizeof__: <built-in method __sizeof__ of function object at 0x7f9a52162e60>\n",
      "__str__: <method-wrapper '__str__' of function object at 0x7f9a52162e60>\n",
      "__subclasshook__: <built-in method __subclasshook__ of type object at 0x56479a10e3c0>\n"
     ]
    }
   ],
   "source": [
    "CutHandler.__init__.__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__annotations__: {}\n",
      "__builtins__: {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f9af5250760>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x7f9af5527370>, 'runfile': <function runfile at 0x7f9af53b5000>, '__IPYTHON__': True, 'display': <function display at 0x7f9af67103a0>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1014__': <capsule object NULL at 0x7f9ad5feb660>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1011__': <capsule object NULL at 0x7f9ab3460030>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9af5251e40>>}\n",
      "__call__: <method-wrapper '__call__' of function object at 0x7f9a521497e0>\n",
      "__class__: <class 'function'>\n",
      "__closure__: None\n",
      "__code__: <code object __init__ at 0x7f9a5289b940, file \"/tmp/ipykernel_4100665/2770846967.py\", line 41>\n",
      "__defaults__: (None, [211, -211, 13, -13, 11, -11, 22, 2212, 321])\n",
      "__delattr__: <method-wrapper '__delattr__' of function object at 0x7f9a521497e0>\n",
      "__dict__: {}\n",
      "__dir__: <built-in method __dir__ of function object at 0x7f9a521497e0>\n",
      "__doc__: \n",
      "        Create new a `CutHandler` object to store applied masks\n",
      "        and return a table of tracked particles when asked.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        evts : Master.Data, optional\n",
      "            Initial events the masks are being applied from.\n",
      "            If not set here, it must be set for getting a\n",
      "            table using `self.set_init_evts(evts)`. Default\n",
      "            is None.\n",
      "        particles_to_tag : list, optional\n",
      "            List of pdg codes to be tracked by the tables.\n",
      "            Default is\n",
      "        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        CutHandler\n",
      "            New `CutHandler` instance.\n",
      "        \n",
      "__eq__: <method-wrapper '__eq__' of function object at 0x7f9a521497e0>\n",
      "__format__: <built-in method __format__ of function object at 0x7f9a521497e0>\n",
      "__ge__: <method-wrapper '__ge__' of function object at 0x7f9a521497e0>\n",
      "__get__: <method-wrapper '__get__' of function object at 0x7f9a521497e0>\n",
      "__getattribute__: <method-wrapper '__getattribute__' of function object at 0x7f9a521497e0>\n",
      "__globals__: {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'Particle.from_pdgid(211)', \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'Particle.from_pdgid(211)', 'dir(Particle.from_pdgid(211))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'cutter = CutHandler2(evts)', 'cutter = CutHandler(evts)', 'cutter.get_table()', 'print(cutter.get_table())', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._gen_particle_cols_array(211)', 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', 'CutHandler._particle_table_cols.dtype', 'np.array(CutHandler._particle_table_cols).dtype', 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._table_data', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter.get_table()', 'cutter.get_table(particles_list=[])', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], latex=True)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22], latex=True)', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], ave_per_event=False)', 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'Particles.from_pdgid(211)', 'Particle.from_pdgid(211)', 'f\"Particle.from_pdgid(211)\"', 'f\"{Particle.from_pdgid(211)}\"', '\"pi+\"', 'dir(Particle.from_pdgid(211))', 'dir(Particle.from_pdgid(211).C)', 'Particle.from_pdgid(211).C', 'dir(Particle.from_pdgid(211).C)', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).pdg_name', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).__str__', 'Particle.from_pdgid(211).__str__()', 'Particle.from_pdgid(211)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.set_init_evts.__doc__', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'dir(CutHandler.__init__)', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")'], '_oh': {4: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 5: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 12: Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], 18: array(<map object at 0x7f9a527c1600>, dtype=object), 19: array(<map object at 0x7f9a527c2c80>, dtype=object), 25: dtype('<U29'), 26: array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), 31: {}, 36:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], 37:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , 38:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 39:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , 43: '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', 44:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 45:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , 46:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , 47:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 51:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , 55:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 57: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 58: 'Particle.from_pdgid(211)', 59: 'pi+', 60: 'pi+', 61: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 62: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 63: <Parity.u: 5>, 64: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 65: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 66: 'pi', 67: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 68: <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, 69: 'pi+', 70: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 73: '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', 74: '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 76: '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 80: 'Test', 81: ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, '_dh': [PosixPath('/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks')], 'In': ['', 'Particle.from_pdgid(211)', \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'Particle.from_pdgid(211)', 'dir(Particle.from_pdgid(211))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'cutter = CutHandler2(evts)', 'cutter = CutHandler(evts)', 'cutter.get_table()', 'print(cutter.get_table())', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._gen_particle_cols_array(211)', 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', 'CutHandler._particle_table_cols.dtype', 'np.array(CutHandler._particle_table_cols).dtype', 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter._table_data', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'print(cutter.get_table())', 'cutter.get_table()', 'cutter.get_table(particles_list=[])', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], latex=True)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22], latex=True)', 'cutter.get_table(particles_list=[22])', 'cutter.get_table(particles_list=[22], ave_per_event=False)', 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', 'cutter = CutHandler(evts)', 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', 'Particles.from_pdgid(211)', 'Particle.from_pdgid(211)', 'f\"Particle.from_pdgid(211)\"', 'f\"{Particle.from_pdgid(211)}\"', '\"pi+\"', 'dir(Particle.from_pdgid(211))', 'dir(Particle.from_pdgid(211).C)', 'Particle.from_pdgid(211).C', 'dir(Particle.from_pdgid(211).C)', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).pdg_name', 'dir(Particle.from_pdgid(211))', 'Particle.from_pdgid(211).__str__', 'Particle.from_pdgid(211).__str__()', 'Particle.from_pdgid(211)', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.set_init_evts.__doc__', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'CutHandler.__init__.__doc__', 'dir(CutHandler.__init__)', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")', 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")'], 'Out': {4: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 5: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 12: Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], 18: array(<map object at 0x7f9a527c1600>, dtype=object), 19: array(<map object at 0x7f9a527c2c80>, dtype=object), 25: dtype('<U29'), 26: array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), 31: {}, 36:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], 37:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , 38:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 39:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , 43: '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', 44:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , 45:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , 46:            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , 47:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 51:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , 55:            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , 57: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 58: 'Particle.from_pdgid(211)', 59: 'pi+', 60: 'pi+', 61: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 62: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 63: <Parity.u: 5>, 64: ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], 65: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 66: 'pi', 67: ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], 68: <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, 69: 'pi+', 70: <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, 73: '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', 74: '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 76: '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 80: 'Test', 81: ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9af5251e40>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f9af5252560>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7f9af5252560>, '_': ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '__': 'Test', '___': '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', 'os': <module 'os' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/os.py'>, 'sys': <module 'sys' (built-in)>, '__vsc_ipynb_file__': '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb', '_i': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_ii': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")', '_iii': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', '_i1': 'Particle.from_pdgid(211)', '_i2': \"# Imports\\nimport sys\\nsys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\\nimport os\\nimport operator\\nimport numpy as np\\nimport awkward as ak\\nimport pandas as pd\\nimport copy\\nfrom particle import Particle\\nimport matplotlib.pyplot as plt\\nfrom python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, Tags\\nfrom apps import photon_pairs\\nimport time\", 'operator': <module 'operator' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/operator.py'>, 'np': <module 'numpy' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/numpy/__init__.py'>, 'ak': <module 'awkward' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/awkward/__init__.py'>, 'pd': <module 'pandas' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/__init__.py'>, 'copy': <module 'copy' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/copy.py'>, 'Particle': <class 'particle.particle.particle.Particle'>, 'plt': <module 'matplotlib.pyplot' from '/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/matplotlib/pyplot.py'>, 'EventSelection': <module 'python.analysis.EventSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/EventSelection.py'>, 'Plots': <module 'python.analysis.Plots' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Plots.py'>, 'vector': <module 'python.analysis.vector' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/vector.py'>, 'PairSelection': <module 'python.analysis.PairSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/PairSelection.py'>, 'Master': <module 'python.analysis.Master' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Master.py'>, 'PFOSelection': <module 'python.analysis.PFOSelection' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/PFOSelection.py'>, 'Tags': <module 'python.analysis.Tags' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/python/analysis/Tags.py'>, 'photon_pairs': <module 'apps.photon_pairs' from '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/apps/photon_pairs.py'>, 'time': <module 'time' (built-in)>, '_i3': 'plt_conf = Plots.PlotConfig()\\nplt_conf.SHOW_PLOT = True\\nplt_conf.SAVE_FOLDER = None\\n# plt_conf.BINS = 30', 'plt_conf': <python.analysis.Plots.PlotConfig object at 0x7f9aec500790>, '_i4': 'Particle.from_pdgid(211)', '_4': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i5': 'dir(Particle.from_pdgid(211))', '_5': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i6': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', 'CutHandler': <class '__main__.CutHandler'>, '_i7': '# This needs to change! Need it to give the cumulative mask since the first mask\\n\\nclass MaskIter():\\n    def __init__(self, start_sigs, masks):\\n        self.sigs = start_sigs\\n        self.masks = masks\\n        self.iter_max = len(masks)\\n        self.index = 0\\n        self.curr_mask = self.masks[self.index]\\n\\n        if self.iter_max != len(self.sigs):\\n            raise ValueError(f\"masks and sigs must have the same length: {self.iter_max} and {len(self.sigs)}\")\\n        if self.index >= self.iter_max:\\n            raise IndexError(f\"Start index {self.index} is out of bounds for masks length of {self.iter_max}\")\\n\\n        self.mask_inds = list(range(self.iter_max))\\n        self.simultaneous_masks = []\\n        simul_list = [False] + [self.check_simul_masks(prev, this) for prev, this in zip(self.sigs[:-1], self.sigs[1:])]\\n        self.next_simul = simul_list[1:] + [False]\\n        self.init_simul = []\\n        last_simul = 0\\n        for i, this_simul in enumerate(simul_list):\\n            if not this_simul:\\n                last_simul = i\\n            self.init_simul.append(last_simul)\\n        return\\n    \\n    def __iter__(self):\\n        self.index = 0\\n        self.curr_mask = self.masks[0]\\n        return self\\n\\n    def check_simul_masks(self, sig1, sig2):\\n        return (sig1[0] == sig2[0]) and ((sig1[1] == sig2[-1]) or (sig1[1] == -1) or (sig2[1] == -1))\\n\\n    def get_mask_func(self, mask, next_simul):\\n        if next_simul:\\n            def apply_mask_func(data):\\n                return mask, data\\n        else:\\n            def apply_mask_func(data):\\n                return mask, data[mask]\\n        return apply_mask_func\\n\\n    def __next__(self):\\n        if self.index >= self.iter_max:\\n            raise StopIteration\\n\\n        if self.init_simul[self.index] == self.index:\\n            self.curr_mask = self.masks[self.index]\\n        else:\\n            self.curr_mask = np.logical_and(self.curr_mask, self.masks[self.index])\\n        self.index += 1\\n        return self.get_mask_func(self.curr_mask, self.next_simul[self.index-1])\\n        \\n    def __getitem__(self, sli : slice):\\n        if (sli.step is not None) and (sli.step < 0):\\n            rev_slice = slice(None, None, -1)\\n            sli = slice(sli.stop + 1, sli.start + 1, abs(sli.step))\\n        else:\\n            rev_slice = slice(None, None, None)\\n        this_index = self.mask_inds[sli]\\n        init_masks = self.init_simul[sli]\\n        next_simuls = self.next_simul[sli]\\n        res = []\\n        last_end = init_masks[0]\\n        curr_mask = self.masks[last_end]\\n        for this_i, init_i, next_simul in zip(this_index, init_masks, next_simuls):\\n            if init_i > last_end:\\n                last_end = init_i\\n                curr_mask = self.masks[last_end]\\n            for new_mask in self.masks[last_end+1:this_i+1]:\\n                curr_mask = np.logical_and(curr_mask, new_mask)\\n            res.append(self.get_mask_func(curr_mask, next_simul))\\n        return res[rev_slice]', 'MaskIter': <class '__main__.MaskIter'>, '_i8': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n        data = self._table_data\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        if initial_concat_index > 0:\\n            start_event_index = self._concat_indicies[initial_concat_index]\\n            data = self._change_table_data_init_count(\\n                self,\\n                data[\"Remaining events\"][start_event_index],\\n                data[\"Remaining PFOs\"][start_event_index])\\n            data[\"Name\"][0] = initial_name\\n        if events_only:\\n            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n        else:\\n            return pd.DataFrame(data)', '_i9': 'file = \"/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root\"\\n\\nevts = Master.Data(file,\\n                         nTuple_type=\"PDSPAnalyser\",\\n                         nEvents=-1,\\n                         start=-1)', 'file': '/scratch/wx21978/pi0/root_files/1GeV_beam_v4_prelim/Prod4a_1GeV_BeamSim_00_prelim.root', 'evts': <python.analysis.Master.Data object at 0x7f9ab20780d0>, '_i10': 'cutter = CutHandler2(evts)', '_i11': 'cutter = CutHandler(evts)', 'cutter': <__main__.CutHandler object at 0x7f9a5276ce20>, '_i12': 'cutter.get_table()', '_12': Empty DataFrame\n",
      "Columns: []\n",
      "Index: [], '_i13': 'print(cutter.get_table())', '_i14': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols))\\n        else:\\n            return np.array(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols))\\n        \\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i15': 'cutter = CutHandler(evts)', '_i16': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i17': 'print(cutter.get_table())', '_i18': 'cutter._gen_particle_cols_array(211)', '_18': array(<map object at 0x7f9a527c1600>, dtype=object), '_i19': 'np.array(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_19': array(<map object at 0x7f9a527c2c80>, dtype=object), '_i20': 'np.from_iter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_i21': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols))', '_i22': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), str)', '_i23': 'np.fromiter(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols), dtype=str, count=4)', '_i24': 'CutHandler._particle_table_cols.dtype', '_i25': 'np.array(CutHandler._particle_table_cols).dtype', '_25': dtype('<U29'), '_i26': 'np.array(list(map(lambda c: f\"{211} {c}\", CutHandler._particle_table_cols)))', '_26': array(['211 remaining', '211 percentage remaining',\n",
      "       '211 relative percentage remaining', '211 average per event'],\n",
      "      dtype='<U33'), '_i27': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i28': 'cutter = CutHandler(evts)', '_i29': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i30': 'print(cutter.get_table())', '_i31': 'cutter._table_data', '_31': {}, '_i32': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i33': 'cutter = CutHandler(evts)', '_i34': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i35': 'print(cutter.get_table())', '_i36': 'cutter.get_table()', '_36':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  pi+ remaining  pi+ percentage remaining  ...  \\\n",
      "0              518.495097          19662                100.000000  ...   \n",
      "1               71.044041          13112                 66.687010  ...   \n",
      "2               18.017329           7904                 40.199369  ...   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  p remaining  \\\n",
      "0                           100.000000                34.974852        83979   \n",
      "1                             2.417508                 0.845520        23616   \n",
      "2                            51.922019                 0.439011        13987   \n",
      "\n",
      "   p percentage remaining  p relative percentage remaining  \\\n",
      "0              100.000000                       100.000000   \n",
      "1               28.121316                        28.121316   \n",
      "2               16.655354                        59.226795   \n",
      "\n",
      "   p average per event  K+ remaining  K+ percentage remaining  \\\n",
      "0             3.549408            36               100.000000   \n",
      "1             0.998140            23                63.888889   \n",
      "2             0.591167            17                47.222222   \n",
      "\n",
      "   K+ relative percentage remaining  K+ average per event  \n",
      "0                        100.000000              0.001522  \n",
      "1                         63.888889              0.000972  \n",
      "2                         73.913043              0.000719  \n",
      "\n",
      "[3 rows x 44 columns], '_i37': 'cutter.get_table(particles_list=[])', '_37':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \n",
      "0              518.495097  \n",
      "1               71.044041  \n",
      "2               18.017329  , '_i38': 'cutter.get_table(particles_list=[22])', '_38':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , '_i39': 'cutter.get_table(particles_list=[22], latex=True)', '_39':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  \\gamma remaining  \\gamma percentage remaining  \\\n",
      "0              518.495097            827505                   100.000000   \n",
      "1               71.044041             20005                     2.417508   \n",
      "2               18.017329             10387                     1.255219   \n",
      "\n",
      "   \\gamma relative percentage remaining  \\gamma average per event  \n",
      "0                            100.000000                 34.974852  \n",
      "1                              2.417508                  0.845520  \n",
      "2                             51.922019                  0.439011  , '_i40': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n            # pfos_to_tag={\\n            #     \"$\" + Particle.from_pdgid(211).latex_name + \"$\":211,\\n            #     \"$\" + Particle.from_pdgid(-211).latex_name + \"$\":-211,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":13,\\n            #     \"$\" + Particle.from_pdgid(13).latex_name + \"$\":-13,\\n            #     \"$\" + Particle.from_pdgid(11).latex_name + \"$\":11,\\n            #     \"$\" + Particle.from_pdgid(-11).latex_name + \"$\":-11,\\n            #     \"$\" + Particle.from_pdgid(22).latex_name + \"$\":22,\\n            #     \"$\" + Particle.from_pdgid(2212).latex_name + \"$\":2212,\\n            #     \"$\" + Particle.from_pdgid(321).latex_name + \"$\":321}):\\n                # \"pi+\":211,\\n                # \"pi-\":-211,\\n                # \"mu-\":13,\\n                # \"mu+\":-13,\\n                # \"e-\":11,\\n                # \"e+\":-11,\\n                # \"photon\":22,\\n                # \"proton\":2212,\\n                # \"K+\":321}):\\n        self._masks = []\\n        self._signatures = []\\n        # self._signature = () # OLD\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        # self._consequtive = () # OLD\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._pre_pfo_init_masks = []\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if not good_mask:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def get_table(\\n            self, initial_concat_index=0, initial_name=\"Initial data\", latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._table_data[col]\\n        # if initial_concat_index > self.concat_index:\\n        #     raise IndexError(\\n        #         f\"Concatenation index {initial_concat_index} out of range, \"\\n        #         + f\"only {self.concat_index} concatenation(s) present.\")\\n        # if initial_concat_index > 0:\\n        #     start_event_index = self._concat_indicies[initial_concat_index]\\n        #     data = self._change_table_data_init_count(\\n        #         self,\\n        #         data[\"Remaining events\"][start_event_index],\\n        #         data[\"Remaining PFOs\"][start_event_index])\\n        #     data[\"Name\"][0] = initial_name\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _append_table_data(self, data):\\n        for i in range(len(self._pfo_table_cols)):\\n            self._table_data[self._pfo_table_cols[i]].append(data[i])\\n        return\\n    \\n    def _update_table_data(self, name):\\n        table_data = [name]\\n        table_data += self._get_remaining_events_data()\\n        table_data += self._get_remaining_pfos_data()\\n        self._append_table_data(table_data)\\n        self._concat_indicies[-1] += 1\\n        return\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._empty_curr_mask_queue()\\n        result._conseq_masks += other._conseq_masks\\n        result._curr_masks = other._curr_masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        renormed_data = result._change_table_data_init_count(\\n            other,\\n            result._table_data[\"Remaining events\"][0],\\n            result._init_pfo_count,\\n            last_pfos_count=result._last_pfo_counts)\\n        result._pfos_init |= other._pfos_init\\n        result._last_pfo_counts = other._last_pfo_counts\\n        for c in result._pfo_table_cols:\\n            result._table_data[c] += renormed_data[c][1:]\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i41': 'cutter = CutHandler(evts)', '_i42': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i43': 'cutter.get_table(particles_list=[22], latex=True)', '_43': '\\\\begin{tabular}{llrrrrrrrrrrr}\\n\\\\toprule\\n{} &          Name &  Remaining events &  Percentage of total events remaining &  Relative percentage events &  Remaining PFOs &  Percentage of total PFOs remaining &  Relative percentage of PFOs &  Average PFOs per event &  \\\\textbackslash gamma remaining &  \\\\textbackslash gamma percentage remaining &  \\\\textbackslash gamma relative percentage remaining &  \\\\textbackslash gamma average per event \\\\\\\\\\n\\\\midrule\\n0 &  Initial data &             23660 &                                 100.0 &                       100.0 &        12267594 &                          100.000000 &                   100.000000 &              518.495097 &            827505 &                   100.000000 &                            100.000000 &                 34.974852 \\\\\\\\\\n1 &      nhits<80 &             23660 &                                 100.0 &                       100.0 &         1680902 &                           13.701970 &                    13.701970 &               71.044041 &             20005 &                     2.417508 &                              2.417508 &                  0.845520 \\\\\\\\\\n2 &    50< p <250 &             23660 &                                 100.0 &                       100.0 &          426290 &                            3.474928 &                    25.360788 &               18.017329 &             10387 &                     1.255219 &                             51.922019 &                  0.439011 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n', '_i44': 'cutter.get_table(particles_list=[22])', '_44':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   Average PFOs per event  gamma remaining  gamma percentage remaining  \\\n",
      "0              518.495097           827505                  100.000000   \n",
      "1               71.044041            20005                    2.417508   \n",
      "2               18.017329            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  gamma average per event  \n",
      "0                           100.000000                34.974852  \n",
      "1                             2.417508                 0.845520  \n",
      "2                            51.922019                 0.439011  , '_i45': 'cutter.get_table(particles_list=[22], ave_per_event=False)', '_45':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Relative percentage events  Remaining PFOs  \\\n",
      "0                       100.0        12267594   \n",
      "1                       100.0         1680902   \n",
      "2                       100.0          426290   \n",
      "\n",
      "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
      "0                          100.000000                   100.000000   \n",
      "1                           13.701970                    13.701970   \n",
      "2                            3.474928                    25.360788   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  \\\n",
      "0           827505                  100.000000   \n",
      "1            20005                    2.417508   \n",
      "2            10387                    1.255219   \n",
      "\n",
      "   gamma relative percentage remaining  \n",
      "0                           100.000000  \n",
      "1                             2.417508  \n",
      "2                            51.922019  , '_i46': 'cutter.get_table(particles_list=[22], ave_per_event=False, relative_percent=False)', '_46':            Name  Remaining events  Percentage of total events remaining  \\\n",
      "0  Initial data             23660                                 100.0   \n",
      "1      nhits<80             23660                                 100.0   \n",
      "2    50< p <250             23660                                 100.0   \n",
      "\n",
      "   Remaining PFOs  Percentage of total PFOs remaining  gamma remaining  \\\n",
      "0        12267594                          100.000000           827505   \n",
      "1         1680902                           13.701970            20005   \n",
      "2          426290                            3.474928            10387   \n",
      "\n",
      "   gamma percentage remaining  \n",
      "0                  100.000000  \n",
      "1                    2.417508  \n",
      "2                    1.255219  , '_i47': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_47':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , '_i48': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_index=0):\\n        result = data\\n        for application_func in self:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg).latex_name} {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg)}$ {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i49': 'cutter = CutHandler(evts)', '_i50': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i51': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_51':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
      "0             827505                    100.000000            19662   \n",
      "1              20005                      2.417508            13112   \n",
      "2              10387                      1.255219             7904   \n",
      "\n",
      "   $pi+$ percentage remaining  \n",
      "0                  100.000000  \n",
      "1                   66.687010  \n",
      "2                   40.199369  , '_i52': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _add_initial_data(self, mask):\\n        self._signatures += [self._get_mask_signature(mask)]\\n        self._get_mask_signature(mask, update=True)\\n        table_data = [\\n            \"Initial data\",\\n            ak.num(mask, axis=0),\\n            100.,\\n            100.]\\n        if self._start_sig[1] == -1:\\n            table_data += [\\n                \"Not supplied\",\"-\",\"-\",\"-\"]\\n        else:\\n            self._pfos_init = True\\n            self._init_pfo_count = ak.count(mask)\\n            self._last_pfo_counts = ak.count(mask, axis=1)\\n            table_data += [\\n                ak.count(mask),\\n                100.,\\n                100.,\\n                ak.count(mask)/ak.num(mask, axis=0)]\\n        self._append_table_data(table_data)\\n        return\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]\\n\\n    def _change_table_data_init_count(\\n            self, cut_obj,\\n            new_init_evts, new_init_pfos,\\n            last_events=None, last_pfos_count=None):\\n        new_data = cut_obj._table_data.copy()\\n        evt_counts = new_data[\"Remaining events\"]\\n        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\\n        new_evts_rel = new_data[\"Relative percentage events\"]\\n        if last_events is not None:\\n            new_evts_rel[0] = 100 * evt_counts[0]/last_events\\n        pfo_counts = new_data[\"Remaining PFOs\"]\\n        recreate_pfo_data = False\\n        if new_init_pfos != \"-\":\\n            if \"-\" not in pfo_counts:\\n                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n            else:\\n                # Need to add thing to catch case of second item being events based\\n                if last_pfos_count is not None:\\n                    recreate_pfo_data = True\\n                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\\n                    counts_to_use += pfo_counts[1+len(counts_to_use):]\\n                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\\n                    pfo_counts = counts_to_use\\n                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\\n                else:\\n                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\\n        else:\\n            new_pfos_full = new_data[\"Remaining PFOs\"]\\n        if recreate_pfo_data:\\n            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\\n        else:\\n            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\\n        if last_pfos_count is not None:\\n            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\\n        if recreate_pfo_data:\\n            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\\n        else:\\n            new_ave_pfos = new_data[\"Average PFOs per event\"]\\n        return {\\n            \"Name\":new_data[\"Name\"],\\n            \"Remaining events\":evt_counts,\\n            \"Percentage of total events remaining\":new_evts_full,\\n            \"Relative percentage events\":new_evts_rel,\\n            \"Remaining PFOs\":pfo_counts,\\n            \"Percentage of total PFOs remaining\":new_pfos_full,\\n            \"Relative percentage of PFOs\":new_pfos_rel,\\n            \"Average PFOs per event\":new_ave_pfos}\\n\\n    # def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\\n    #     data = self._table_data\\n    #     if initial_concat_index > self.concat_index:\\n    #         raise IndexError(\\n    #             f\"Concatenation index {initial_concat_index} out of range, \"\\n    #             + f\"only {self.concat_index} concatenation(s) present.\")\\n    #     if initial_concat_index > 0:\\n    #         start_event_index = self._concat_indicies[initial_concat_index]\\n    #         data = self._change_table_data_init_count(\\n    #             self,\\n    #             data[\"Remaining events\"][start_event_index],\\n    #             data[\"Remaining PFOs\"][start_event_index])\\n    #         data[\"Name\"][0] = initial_name\\n    #     if events_only:\\n    #         return pd.DataFrame({key:data[key] for key in self._event_table_cols})\\n    #     else:\\n    #         return pd.DataFrame(data)', '_i53': 'cutter = CutHandler(evts)', '_i54': 'cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\\ncutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")', '_i55': 'cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)', '_55':            Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
      "0  Initial data        12267594                          100.000000   \n",
      "1      nhits<80         1680902                           13.701970   \n",
      "2    50< p <250          426290                            3.474928   \n",
      "\n",
      "   gamma remaining  gamma percentage remaining  pi+ remaining  \\\n",
      "0           827505                  100.000000          19662   \n",
      "1            20005                    2.417508          13112   \n",
      "2            10387                    1.255219           7904   \n",
      "\n",
      "   pi+ percentage remaining  \n",
      "0                100.000000  \n",
      "1                 66.687010  \n",
      "2                 40.199369  , '_i56': 'Particles.from_pdgid(211)', '_i57': 'Particle.from_pdgid(211)', '_57': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i58': 'f\"Particle.from_pdgid(211)\"', '_58': 'Particle.from_pdgid(211)', '_i59': 'f\"{Particle.from_pdgid(211)}\"', '_59': 'pi+', '_i60': '\"pi+\"', '_60': 'pi+', '_i61': 'dir(Particle.from_pdgid(211))', '_61': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i62': 'dir(Particle.from_pdgid(211).C)', '_62': ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], '_i63': 'Particle.from_pdgid(211).C', '_63': <Parity.u: 5>, '_i64': 'dir(Particle.from_pdgid(211).C)', '_64': ['__class__', '__doc__', '__module__', 'as_integer_ratio', 'bit_count', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'name', 'numerator', 'real', 'to_bytes', 'value'], '_i65': 'dir(Particle.from_pdgid(211))', '_65': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i66': 'Particle.from_pdgid(211).pdg_name', '_66': 'pi', '_i67': 'dir(Particle.from_pdgid(211))', '_67': ['C', 'G', 'I', 'J', 'L', 'P', 'S', '__annotations__', '__attrs_attrs__', '__attrs_own_setattr__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__neg__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_charge_in_name', '_from_group_dict_list', '_hash_table', '_repr_latex_', '_str_charge', '_str_mass', '_table', '_table_names', '_three_charge', '_width_or_lifetime', 'all', 'anti_flag', 'charge', 'ctau', 'describe', 'empty', 'evtgen_name', 'findall', 'finditer', 'from_evtgen_name', 'from_name', 'from_nucleus_info', 'from_pdgid', 'from_string', 'from_string_list', 'html_name', 'invert', 'is_name_barred', 'is_self_conjugate', 'is_unflavoured_meson', 'latex_name', 'lifetime', 'load_table', 'mass', 'mass_lower', 'mass_upper', 'name', 'pdg_name', 'pdgid', 'programmatic_name', 'quarks', 'rank', 'spin_type', 'status', 'table_loaded', 'table_names', 'three_charge', 'to_dict', 'to_list', 'width', 'width_lower', 'width_upper'], '_i68': 'Particle.from_pdgid(211).__str__', '_68': <bound method Particle.__str__ of <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>>, '_i69': 'Particle.from_pdgid(211).__str__()', '_69': 'pi+', '_i70': 'Particle.from_pdgid(211)', '_70': <Particle: name=\"pi+\", pdgid=211, mass=139.57039  0.00018 MeV>, '_i71': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc():\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        def doc_func(func):\\n            func.__doc__ = documentation\\n            return func\\n        return doc_func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i72': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i73': 'CutHandler.set_init_evts.__doc__', '_73': '\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        ', '_i74': 'CutHandler.__init__.__doc__', '_74': '\\n        Create a `CutHandler` object to \\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', '_i75': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n    \\n    __doc__ = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{_default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i76': 'CutHandler.__init__.__doc__', '_76': '\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        [211, -211, 13, -13, 11, -11, 22, 2212, 321].\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        ', '_i77': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i78': 'CutHandler.__init__.__doc__', '_i79': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    # @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        \"\"\"Test\"\"\"\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i80': 'CutHandler.__init__.__doc__', '_80': 'Test', '_i81': 'dir(CutHandler.__init__)', '_81': ['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '_i82': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\"CutHandler.__init__.\"+prop)}\")', '_i83': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")', 'prop': '__globals__', '_i84': 'class CutHandler():\\n    _default_particles = [\\n        211, -211, 13, -13,\\n        11, -11, 22, 2212, 321]\\n    _event_table_cols = np.array([\\n            \"Remaining events\", \"Percentage of total events remaining\",\\n            \"Relative percentage events\"])\\n    _pfo_table_cols = np.array([\\n            \"Remaining PFOs\", \"Percentage of total PFOs remaining\",\\n            \"Relative percentage of PFOs\", \"Average PFOs per event\"])\\n    _particle_table_cols = [\\n            \"remaining\", \"percentage remaining\",\\n            \"relative percentage remaining\", \"average per event\"]\\n\\n    @staticmethod\\n    def _init_doc(func):\\n        documentation = \"\"\"\\n        Create new a `CutHandler` object to store applied masks\\n        and return a table of tracked particles when asked.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data, optional\\n            Initial events the masks are being applied from.\\n            If not set here, it must be set for getting a\\n            table using `self.set_init_evts(evts)`. Default\\n            is None.\\n        particles_to_tag : list, optional\\n            List of pdg codes to be tracked by the tables.\\n            Default is\\n        \"\"\" + f\"{CutHandler._default_particles}.\" + \"\"\"\\n        \\n        Returns\\n        -------\\n        CutHandler\\n            New `CutHandler` instance.\\n        \"\"\"\\n        func.__doc__ = documentation\\n        return func\\n\\n    @_init_doc\\n    def __init__(\\n            self,\\n            evts=None,\\n            particles_to_tag=_default_particles):\\n        self._masks = []\\n        self._signatures = []\\n        self._start_sig = ()\\n        self._end_sig = ()\\n        self.concat_index = 0\\n        self._concat_indicies = [0]\\n        self._pfos_init = False\\n        self._init_data = None\\n        self._particle_tags = None\\n        self._data_changed = True\\n        self.init_events_set = False\\n        if evts is not None:\\n            self.set_init_evts(evts)\\n        self._last_pfo_counts = None\\n        self._names=[]\\n\\n        self._particles = particles_to_tag\\n\\n        self._table_data = {}\\n        return\\n\\n    def _gen_basic_counts(self):\\n        init_evt_count = ak.num(self._init_data, axis=0)\\n        init_pfo_count = ak.count(self._init_data)\\n        results = {\\n            \"Name\":[\"Initial data\"],\\n            \"Remaining events\":[init_evt_count],\\n            \"Percentage of total events remaining\":[100.],\\n            \"Relative percentage events\":[100.],\\n            \"Remaining PFOs\":[init_pfo_count],\\n            \"Percentage of total PFOs remaining\":[100.],\\n            \"Relative percentage of PFOs\":[100.],\\n            \"Average PFOs per event\":[init_pfo_count/init_evt_count]}\\n        last_evt_count = init_evt_count\\n        last_pfo_count = init_pfo_count\\n        data = self._init_data\\n        for name, application_func in zip(self._names, self):\\n            this_mask, new_data = application_func(data)\\n            this_evt_count = ak.num(data[this_mask], axis=0)\\n            this_pfo_count = ak.count(data[this_mask])\\n            results[\"Name\"].append(name)\\n            results[\"Remaining events\"].append(this_evt_count)\\n            results[\"Percentage of total events remaining\"].append(100.*this_evt_count/init_evt_count)\\n            results[\"Relative percentage events\"].append(100.*this_evt_count/last_evt_count)\\n            results[\"Remaining PFOs\"].append(this_pfo_count)\\n            results[\"Percentage of total PFOs remaining\"].append(100.*this_pfo_count/init_pfo_count)\\n            results[\"Relative percentage of PFOs\"].append(100.*this_pfo_count/last_pfo_count)\\n            results[\"Average PFOs per event\"].append(this_pfo_count/this_evt_count)\\n            last_evt_count = this_evt_count\\n            last_pfo_count = this_pfo_count\\n            data = new_data\\n        return results\\n\\n    def _gen_particle_counts(self, init_list):\\n        init_count = np.sum(init_list)\\n        results = {\\n            \"remaining\": [init_count],\\n            \"percentage remaining\": [100.],\\n            \"relative percentage remaining\": [100.],\\n            \"average per event\": [init_count/ak.num(init_list, axis=0)]}\\n        data = init_list\\n        for application_func in self:\\n            this_mask, new_data = application_func(data)\\n            particle_count = np.sum(data[this_mask])\\n            results[\"remaining\"].append(particle_count)\\n            results[\"percentage remaining\"].append(100. * particle_count/init_count)\\n            results[\"relative percentage remaining\"].append(\\n                100. * particle_count/results[\"remaining\"][-2])\\n            results[\"average per event\"].append(particle_count/ak.num(data[this_mask], axis=0))\\n            data = new_data\\n        return results\\n\\n    # def GeneratePi0Tags(self, evts : Master.Data):\\n    #     photons_mask = evts.trueParticlesBT.pdg == 22\\n    #     return Tags.GeneratePi0Tags(evts, photons_mask)\\n\\n    def set_init_evts(self, evts : Master.Data):\\n        \"\"\"\\n        Set the initial event counts to be cut using the masks.\\n        This is automatically performed if as `Master.Data`\\n        object is passed in initialisation.\\n        \\n        This must be performed prior to generating a table.\\n\\n        Use `self.init_data_set` for a boolean indicating if\\n        the events have been set.\\n\\n        N.B. if we want to to this for truth, we must change evts\\n        to be an acutal akward array (i.e.\\n        `evts.recoParticles.number` for reco and\\n        `evts.trueParticles.number` for truth). At the moment,\\n        we take a Master.Data object an pull the\\n        `evts.recoParticles.number` from it.\\n\\n        Parameters\\n        ----------\\n        evts : Master.Data\\n            Initial events the masks are being applied from.\\n        \"\"\"\\n        self._init_data = ak.ones_like(evts.recoParticles.number, dtype=bool)\\n        self._init_data_sig = self._get_mask_signature(self._init_data)\\n        self._particle_tags = Tags.GenerateTrueParticleTags(evts)\\n        self._data_changed = True\\n        self.init_events_set = True\\n        return\\n\\n    def _get_mask_signature(self, mask, end=False):\\n        flat_array = isinstance(ak.count(mask, axis=0), int)\\n        if not end:\\n            pfo_level = -1 if flat_array else ak.count(mask)\\n            start_sig = (ak.num(mask, axis=0), pfo_level)\\n            return start_sig\\n        if flat_array:\\n            end_sig = (ak.sum(mask), -1)\\n        else:\\n            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\\n        return end_sig\\n    \\n    def _validate_signature(self, signature, raise_exception=True):\\n        if self._start_sig == ():\\n            return\\n        simul_mask = (self._start_sig[0] == signature[0]) and ((self._start_sig[-1] == signature[-1]) or (self._start_sig[-1] == -1) or (signature[-1] == -1))\\n        good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((self._end_sig[-1] == signature[-1]) or (self._end_sig[-1] == -1) or (signature[-1] == -1)))\\n        if (not good_mask) and raise_exception:\\n            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n                             + f\" the required signature of ({self._start_sig[0]} events, \"\\n                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\\n                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\\n        return good_mask\\n\\n    def add_mask(self, mask, name):\\n        this_sig = self._get_mask_signature(mask)\\n        self._validate_signature(this_sig)\\n        self._start_sig = this_sig\\n        self._end_sig = self._get_mask_signature(mask, end=True)\\n        self._masks.append(mask)\\n        self._signatures.append(this_sig)\\n        self._names.append(name)\\n        return\\n\\n    def _mask_appliers(self):\\n        return MaskIter(self._signatures, self._masks)\\n\\n    def __iter__(self):\\n        return self._mask_appliers()\\n\\n    def copy(self):\\n        return copy.deepcopy(self)\\n    \\n    def apply_masks(self, data, return_table=False, application_concat_index=0):\\n        result = data\\n        for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n            _, result = application_func(result)\\n        if return_table:\\n            return result, self.get_table()\\n        else:\\n            return result\\n    \\n    # def get_filters_list(self, application_concat_index=0):\\n    #     new_data = data\\n    #     for application_func in self._mask_appliers()[self._concat_indicies[application_concat_index]:]:\\n    #         mask, _ = application_func(result)\\n        \\n\\n    def _gen_table(self):\\n        if self._init_data is None:\\n            raise Exception(\"Initial data not added, supply events using set_init_events.\")\\n        if not self._data_changed:\\n            return\\n        self._table_data.update(self._gen_basic_counts())\\n        for particle in self._particles:\\n            p_data = self._gen_particle_counts(self._particle_tags[f\"${Particle.from_pdgid(particle).latex_name}$\"].mask)\\n            self._table_data.update(dict((f\"{particle} {key}\", value) for (key, value) in p_data.items()))\\n        self._data_changed = False\\n        return\\n\\n        # if not self._check_signature(self._get_mask_signature(self._masks[0]), self._init_data_sig):\\n        #     raise ValueError(f\"Initial data signature {self._init_data_sig} does not match the first avaiable mask {self._get_mask_signature(self._masks[0])}\")\\n    \\n    def _gen_particle_cols_array(self, pdg):\\n        return np.array(list(map(lambda c: f\"{pdg} {c}\", self._particle_table_cols)))\\n    def _gen_particle_cols_array_read(self, pdg, latex):\\n        if latex:\\n            return np.array(list(map(lambda c: f\"${Particle.from_pdgid(pdg).latex_name}$ {c}\", self._particle_table_cols)))\\n        else:\\n            return np.array(list(map(lambda c: f\"{Particle.from_pdgid(pdg)} {c}\", self._particle_table_cols)))\\n\\n    def _new_init_events(self, col, index, init_name):\\n        if index == 0:\\n            result = self._table_data[col]\\n        else:\\n            result = self._table_data[col][index:]\\n            if \"percentage\" in col.lower():\\n                result[0] = 100.\\n        if col == \"Name\":\\n            result[0] = init_name\\n        return result\\n\\n    def get_table(\\n            self, init_data_name = \"Initial data\", initial_concat_index=0, latex=False,\\n            events=True, pfos=True, particles_list=_default_particles,\\n            counts=True, percent_remain=True, relative_percent=True, ave_per_event=True):\\n        if initial_concat_index > self.concat_index:\\n            raise IndexError(\\n                f\"Concatenation index {initial_concat_index} out of range, \"\\n                + f\"only {self.concat_index} concatenation(s) present.\")\\n        cols_to_use = [\"Name\"]\\n        col_names = [\"Name\"]\\n        cols_to_keep = np.array([counts, percent_remain, relative_percent, ave_per_event])\\n        if events:\\n            cols = self._event_table_cols[cols_to_keep[:-1]].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        if pfos:\\n            cols = self._pfo_table_cols[cols_to_keep].tolist()\\n            cols_to_use += cols\\n            col_names += cols\\n        for p in particles_list:\\n            cols_to_use += self._gen_particle_cols_array(p)[cols_to_keep].tolist()\\n            col_names += self._gen_particle_cols_array_read(p, latex)[cols_to_keep].tolist()\\n        \\n        self._gen_table()\\n        data = {}\\n        for col, name in zip(cols_to_use, col_names):\\n            data[name] = self._new_init_events(\\n                col, self._concat_indicies[initial_concat_index], init_data_name)\\n        if latex:\\n            return pd.DataFrame(data).to_latex()\\n        else:\\n            return pd.DataFrame(data)\\n\\n    def concatenate(self, other, return_copy=False):\\n        if not isinstance(other, CutHandler):\\n            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\\n        # Make sure the new set is consequtive\\n        if not self._validate_signature(other._signatures[0], raise_exception=False):\\n            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\\n                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\\n        if return_copy:\\n            result = self.copy()\\n        else:\\n            result = self\\n        result._masks = other._masks\\n        result._signatures += other._signatures[1:]\\n        result._start_sig = other._start_sig\\n        result._end_sig = other._end_sig\\n        result.concat_index += 1\\n        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\\n        if (result._init_data is None) and (other._init_data is not None):\\n            result._init_data = other._init_data\\n            result._init_data_sig = other._init_data_sig\\n            result._data_changed = True\\n            result.init_events_set = other.init_events_set\\n            if result._particles != other._particles:\\n                warnings.warn(\"Concatenated data has a different set of watched particles, re-running set_init_evts() is recommended.\")\\n            result._particle_tags = other._particle_tags\\n        if return_copy:\\n            return result\\n        else:\\n            return\\n\\n    def __add__(self, other):\\n        return self.concatenate(other, return_copy=True)\\n\\n\\n\\n    # ----------------------------------------------------------------\\n\\n    # def _validate_signature(self, signature):\\n    #     if not self._check_signature(signature):\\n    #         if self._consequtive:\\n    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\\n    #         else:\\n    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\\n    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\\n    #                             + f\" the required signature for {conseq_text}.\\\\nRequired signature is \"\\n    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\\n\\n    def _get_remaining_events_data(self):\\n        this_sig = self._signatures[-1]\\n        if this_sig[1] == -1:\\n            curr_remaining = ak.sum(self.get_curr_mask())\\n        else:\\n            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\\n        init_remaining = self._table_data[\"Remaining events\"][0]\\n        last_remaining = self._table_data[\"Remaining events\"][-1]\\n        return [curr_remaining,\\n                100 * curr_remaining/init_remaining,\\n                100 * curr_remaining/last_remaining]\\n    \\n    def _get_remaining_pfos_data(self):\\n        this_sig = self._signatures[-1]\\n        if not self._pfos_init:\\n            if this_sig[1] == -1:\\n                self._pre_pfo_init_masks += [self.get_curr_mask()]\\n                return [\"-\", \"-\", \"-\", \"-\"]\\n            else:\\n                self._pfos_init = True\\n                this_mask = self.get_curr_mask()\\n                self._init_pfo_count = ak.count(this_mask)\\n                last_remaining = ak.sum(self._init_pfo_count)\\n        else:\\n            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\\n        if this_sig[1] == -1:\\n            this_mask = self.get_curr_mask()\\n            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\\n            curr_events_remaining = ak.sum(this_mask)\\n            return [\\n                curr_remaining,\\n                0.,\\n                100.,\\n                curr_remaining/curr_events_remaining]\\n        else:\\n            this_mask = self.get_curr_mask()\\n            self._last_pfo_counts = ak.count(this_mask, axis=1)\\n            curr_remaining = ak.sum(this_mask)\\n            curr_events_remaining = ak.num(this_mask, axis=0)\\n        return [curr_remaining,\\n                100 * curr_remaining/self._init_pfo_count,\\n                100 * curr_remaining/last_remaining,\\n                curr_remaining/curr_events_remaining]', '_i85': 'for prop in dir(CutHandler.__init__):\\n    print(f\"{prop}: {eval(\\'CutHandler.__init__.\\'+prop)}\")'}\n",
      "__gt__: <method-wrapper '__gt__' of function object at 0x7f9a521497e0>\n",
      "__hash__: <method-wrapper '__hash__' of function object at 0x7f9a521497e0>\n",
      "__init__: <method-wrapper '__init__' of function object at 0x7f9a521497e0>\n",
      "__init_subclass__: <built-in method __init_subclass__ of type object at 0x56479a10e3c0>\n",
      "__kwdefaults__: None\n",
      "__le__: <method-wrapper '__le__' of function object at 0x7f9a521497e0>\n",
      "__lt__: <method-wrapper '__lt__' of function object at 0x7f9a521497e0>\n",
      "__module__: __main__\n",
      "__name__: __init__\n",
      "__ne__: <method-wrapper '__ne__' of function object at 0x7f9a521497e0>\n",
      "__new__: <built-in method __new__ of type object at 0x56479a10e3c0>\n",
      "__qualname__: CutHandler.__init__\n",
      "__reduce__: <built-in method __reduce__ of function object at 0x7f9a521497e0>\n",
      "__reduce_ex__: <built-in method __reduce_ex__ of function object at 0x7f9a521497e0>\n",
      "__repr__: <method-wrapper '__repr__' of function object at 0x7f9a521497e0>\n",
      "__setattr__: <method-wrapper '__setattr__' of function object at 0x7f9a521497e0>\n",
      "__sizeof__: <built-in method __sizeof__ of function object at 0x7f9a521497e0>\n",
      "__str__: <method-wrapper '__str__' of function object at 0x7f9a521497e0>\n",
      "__subclasshook__: <built-in method __subclasshook__ of type object at 0x56479a10e3c0>\n"
     ]
    }
   ],
   "source": [
    "for prop in dir(CutHandler.__init__):\n",
    "    print(f\"{prop}: {eval('CutHandler.__init__.'+prop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = CutHandler(evts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter.add_mask(evts.recoParticles.nHits > 80, \"nhits<80\")\n",
    "cutter.add_mask(np.logical_and(evts.recoParticles.energy > 50, evts.recoParticles.energy < 250), \"50< p <250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/compat/_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    139\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jinja2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cutter\u001b[39m.\u001b[39;49mget_table(particles_list\u001b[39m=\u001b[39;49m[\u001b[39m22\u001b[39;49m, \u001b[39m211\u001b[39;49m], ave_per_event\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, relative_percent\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, events\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39;49mstyle\u001b[39m.\u001b[39mto_latex()\n",
      "File \u001b[0;32m/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/core/frame.py:1212\u001b[0m, in \u001b[0;36mDataFrame.style\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstyle\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Styler:\n\u001b[1;32m   1202\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[39m    Returns a Styler object.\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[39m        data with HTML and CSS.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1212\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle\u001b[39;00m \u001b[39mimport\u001b[39;00m Styler\n\u001b[1;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m Styler(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/io/formats/style.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mshared_docs\u001b[39;00m \u001b[39mimport\u001b[39;00m _shared_docs\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformat\u001b[39;00m \u001b[39mimport\u001b[39;00m save_to_buffer\n\u001b[0;32m---> 52\u001b[0m jinja2 \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mjinja2\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDataFrame.style requires jinja2.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle_render\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     55\u001b[0m     CSSProperties,\n\u001b[1;32m     56\u001b[0m     CSSStyles,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     refactor_levels,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/software/wx21978/miniconda/envs/pi0-phys/lib/python3.10/site-packages/pandas/compat/_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    142\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2."
     ]
    }
   ],
   "source": [
    "cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False, latex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>$gamma$ remaining</th>\n",
       "      <th>$gamma$ percentage remaining</th>\n",
       "      <th>$pi+$ remaining</th>\n",
       "      <th>$pi+$ percentage remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>12267594</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>827505</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19662</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhits&lt;80</td>\n",
       "      <td>1680902</td>\n",
       "      <td>13.701970</td>\n",
       "      <td>20005</td>\n",
       "      <td>2.417508</td>\n",
       "      <td>13112</td>\n",
       "      <td>66.687010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50&lt; p &lt;250</td>\n",
       "      <td>426290</td>\n",
       "      <td>3.474928</td>\n",
       "      <td>10387</td>\n",
       "      <td>1.255219</td>\n",
       "      <td>7904</td>\n",
       "      <td>40.199369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining PFOs  Percentage of total PFOs remaining  \\\n",
       "0  Initial data        12267594                          100.000000   \n",
       "1      nhits<80         1680902                           13.701970   \n",
       "2    50< p <250          426290                            3.474928   \n",
       "\n",
       "   $gamma$ remaining  $gamma$ percentage remaining  $pi+$ remaining  \\\n",
       "0             827505                    100.000000            19662   \n",
       "1              20005                      2.417508            13112   \n",
       "2              10387                      1.255219             7904   \n",
       "\n",
       "   $pi+$ percentage remaining  \n",
       "0                  100.000000  \n",
       "1                   66.687010  \n",
       "2                   40.199369  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter.get_table(particles_list=[22, 211], ave_per_event=False, relative_percent=False, events=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "      <th>$\\pi^{+}$ remaining</th>\n",
       "      <th>$\\pi^{+}$ percentage remaining</th>\n",
       "      <th>...</th>\n",
       "      <th>$\\gamma$ relative percentage remaining</th>\n",
       "      <th>$\\gamma$ average per event</th>\n",
       "      <th>$p$ remaining</th>\n",
       "      <th>$p$ percentage remaining</th>\n",
       "      <th>$p$ relative percentage remaining</th>\n",
       "      <th>$p$ average per event</th>\n",
       "      <th>$K^{+}$ remaining</th>\n",
       "      <th>$K^{+}$ percentage remaining</th>\n",
       "      <th>$K^{+}$ relative percentage remaining</th>\n",
       "      <th>$K^{+}$ average per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>23660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12267594</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>518.495097</td>\n",
       "      <td>19662</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.974852</td>\n",
       "      <td>83979</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.549408</td>\n",
       "      <td>36</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.001522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhits&lt;80</td>\n",
       "      <td>23660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1680902</td>\n",
       "      <td>13.701970</td>\n",
       "      <td>13.701970</td>\n",
       "      <td>71.044041</td>\n",
       "      <td>13112</td>\n",
       "      <td>66.687010</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417508</td>\n",
       "      <td>0.845520</td>\n",
       "      <td>23616</td>\n",
       "      <td>28.121316</td>\n",
       "      <td>28.121316</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>23</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50&lt; p &lt;250</td>\n",
       "      <td>23660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>426290</td>\n",
       "      <td>3.474928</td>\n",
       "      <td>25.360788</td>\n",
       "      <td>18.017329</td>\n",
       "      <td>7904</td>\n",
       "      <td>40.199369</td>\n",
       "      <td>...</td>\n",
       "      <td>51.922019</td>\n",
       "      <td>0.439011</td>\n",
       "      <td>13987</td>\n",
       "      <td>16.655354</td>\n",
       "      <td>59.226795</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>17</td>\n",
       "      <td>47.222222</td>\n",
       "      <td>73.913043</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data             23660                                 100.0   \n",
       "1      nhits<80             23660                                 100.0   \n",
       "2    50< p <250             23660                                 100.0   \n",
       "\n",
       "   Relative percentage events  Remaining PFOs  \\\n",
       "0                       100.0        12267594   \n",
       "1                       100.0         1680902   \n",
       "2                       100.0          426290   \n",
       "\n",
       "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
       "0                          100.000000                   100.000000   \n",
       "1                           13.701970                    13.701970   \n",
       "2                            3.474928                    25.360788   \n",
       "\n",
       "   Average PFOs per event  $\\pi^{+}$ remaining  \\\n",
       "0              518.495097                19662   \n",
       "1               71.044041                13112   \n",
       "2               18.017329                 7904   \n",
       "\n",
       "   $\\pi^{+}$ percentage remaining  ...  \\\n",
       "0                      100.000000  ...   \n",
       "1                       66.687010  ...   \n",
       "2                       40.199369  ...   \n",
       "\n",
       "   $\\gamma$ relative percentage remaining  $\\gamma$ average per event  \\\n",
       "0                              100.000000                   34.974852   \n",
       "1                                2.417508                    0.845520   \n",
       "2                               51.922019                    0.439011   \n",
       "\n",
       "   $p$ remaining  $p$ percentage remaining  $p$ relative percentage remaining  \\\n",
       "0          83979                100.000000                         100.000000   \n",
       "1          23616                 28.121316                          28.121316   \n",
       "2          13987                 16.655354                          59.226795   \n",
       "\n",
       "   $p$ average per event  $K^{+}$ remaining  $K^{+}$ percentage remaining  \\\n",
       "0               3.549408                 36                    100.000000   \n",
       "1               0.998140                 23                     63.888889   \n",
       "2               0.591167                 17                     47.222222   \n",
       "\n",
       "   $K^{+}$ relative percentage remaining  $K^{+}$ average per event  \n",
       "0                             100.000000                   0.001522  \n",
       "1                              63.888889                   0.000972  \n",
       "2                              73.913043                   0.000719  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cutter._table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter._gen_table()\n",
    "print(cutter._table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutHandlerOld():\n",
    "    def __init__(self):\n",
    "        self._curr_masks = []\n",
    "        self._conseq_masks = []\n",
    "        self._signatures = []\n",
    "        # self._signature = () # OLD\n",
    "        self._start_sig = ()\n",
    "        self._end_sig = ()\n",
    "        # self._consequtive = () # OLD\n",
    "        self.concat_index = 0\n",
    "        self._concat_indicies = [0]\n",
    "        self._pfos_init = False\n",
    "        self._pre_pfo_init_masks = []\n",
    "        self._init_pfo_count = np.inf\n",
    "        self._last_pfo_counts = None\n",
    "        self._pfo_table_cols = [\n",
    "            \"Name\", \"Remaining events\", \"Percentage of total events remaining\",\n",
    "            \"Relative percentage events\", \"Remaining PFOs\",\n",
    "            \"Percentage of total PFOs remaining\", \"Relative percentage of PFOs\",\n",
    "            \"Average PFOs per event\"]\n",
    "        self._event_table_cols = [\n",
    "            \"Name\", \"Remaining events\", \"Percentage of total events remaining\",\n",
    "            \"Relative percentage events\"]\n",
    "        self._event_inds_indicies = []\n",
    "\n",
    "        self._table_data = {}\n",
    "        for col in self._pfo_table_cols:\n",
    "            self._table_data.update({col:[]})\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return MaskIter(self._signatures, self._masks, init_step=self.curr_concat_index)\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def _get_mask_signature(self, mask, end=False, update=False):\n",
    "        flat_array = isinstance(ak.count(mask, axis=0), int)\n",
    "        if update or (not end):\n",
    "            pfo_level = -1 if flat_array else ak.count(mask)\n",
    "            start_sig = (ak.num(mask, axis=0), pfo_level)\n",
    "            if not update:\n",
    "                return start_sig\n",
    "        if flat_array:\n",
    "            end_sig = (ak.sum(mask), -1)\n",
    "        else:\n",
    "            end_sig = (ak.num(mask, axis=0), ak.sum(mask))\n",
    "        if not update:\n",
    "            return end_sig\n",
    "        # if update is True\n",
    "        self._start_sig = start_sig\n",
    "        self._end_sig = end_sig\n",
    "        return\n",
    "    \n",
    "    def _get_last_pfo_sig(self):\n",
    "        if not self._pfos_init:\n",
    "            return -1, -1\n",
    "        else:\n",
    "            last_full = self._table_data[\"Percentage of total PFOs remaining\"]/100\n",
    "            last_relative = self._table_data[\"Relative percentage of PFOs\"]/100\n",
    "            last_start = round(last_full * self._init_pfo_count)\n",
    "            last_end = round(last_start/last_relative)\n",
    "            return last_start, last_end\n",
    "\n",
    "    def _check_signature(self, signature):\n",
    "        # simul_mask = (self._start_sig[0] == signature[0]) and ((start_pfo == signature[-1]) or (start_pfo == -1) or (signature[-1] == -1))\n",
    "        # good_mask = simul_mask or (self._end_sig[0] == signature[0] and ((end_pfo == signature[-1]) or (end_pfo == -1) or (signature[-1] == -1)))\n",
    "        good_mask = False\n",
    "        if signature[-1] != -1:\n",
    "            if self._start_sig[1] == -1:\n",
    "                start_pfo, end_pfo = self._get_last_pfo_sig()\n",
    "            else:\n",
    "                start_pfo = self._start_sig[1]\n",
    "                end_pfo = self._end_sig[1]\n",
    "        else:\n",
    "            start_pfo = -1\n",
    "            end_pfo = -1\n",
    "        if (self._start_sig[0] == signature[0]):\n",
    "            simul_mask = True\n",
    "            good_mask = (start_pfo == signature[-1]) or (start_pfo == -1)\n",
    "        elif (self._end_sig[0] == signature[0]):\n",
    "            simul_mask = False\n",
    "            good_mask = (end_pfo == signature[-1]) or (end_pfo == -1)\n",
    "        if not good_mask:\n",
    "            raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\n",
    "                             + f\" the required signature of ({self._start_sig[0]} events, \"\n",
    "                             + f\"{self._start_sig[1]} PFOs) for a simultaenous mask, or ({self._end_sig[0]}\"\n",
    "                             + f\" events, {self._end_sig[1]} PFOs) for a consequtive mask.\")\n",
    "        return simul_mask\n",
    "\n",
    "    # def _validate_signature(self, signature):\n",
    "    #     if not self._check_signature(signature):\n",
    "    #         if self._consequtive:\n",
    "    #             conseq_text = \"consequtive masks (each mask has input signature of the output of the previous mask)\"\n",
    "    #         else:\n",
    "    #             conseq_text = \"initially matched masks (each mask must have the same input signature)\"\n",
    "    #         raise ValueError(f\"Mask signature ({signature[0]} events, {signature[1]} PFOs) does not match\"\n",
    "    #                             + f\" the required signature for {conseq_text}.\\nRequired signature is \"\n",
    "    #                             + f\"({self._signature[0]} events, {self._signature[1]} PFOs).\")\n",
    "\n",
    "    def _add_initial_data(self, mask):\n",
    "        self._signatures += [self._get_mask_signature(mask)]\n",
    "        self._get_mask_signature(mask, update=True)\n",
    "        table_data = [\n",
    "            \"Initial data\",\n",
    "            ak.num(mask, axis=0),\n",
    "            100.,\n",
    "            100.]\n",
    "        if self._start_sig[1] == -1:\n",
    "            table_data += [\n",
    "                \"Not supplied\",\"-\",\"-\",\"-\"]\n",
    "        else:\n",
    "            self._pfos_init = True\n",
    "            self._init_pfo_count = ak.count(mask)\n",
    "            self._last_pfo_counts = ak.count(mask, axis=1)\n",
    "            table_data += [\n",
    "                ak.count(mask),\n",
    "                100.,\n",
    "                100.,\n",
    "                ak.count(mask)/ak.num(mask, axis=0)]\n",
    "        self._append_table_data(table_data)\n",
    "        return\n",
    "\n",
    "    def _get_remaining_events_data(self):\n",
    "        this_sig = self._signatures[-1]\n",
    "        if this_sig[1] == -1:\n",
    "            curr_remaining = ak.sum(self.get_curr_mask())\n",
    "        else:\n",
    "            curr_remaining = ak.num(self.get_curr_mask(), axis=0)\n",
    "        init_remaining = self._table_data[\"Remaining events\"][0]\n",
    "        last_remaining = self._table_data[\"Remaining events\"][-1]\n",
    "        return [curr_remaining,\n",
    "                100 * curr_remaining/init_remaining,\n",
    "                100 * curr_remaining/last_remaining]\n",
    "    \n",
    "    def _get_remaining_pfos_data(self):\n",
    "        this_sig = self._signatures[-1]\n",
    "        if not self._pfos_init:\n",
    "            if this_sig[1] == -1:\n",
    "                self._pre_pfo_init_masks += [self.get_curr_mask()]\n",
    "                return [\"-\", \"-\", \"-\", \"-\"]\n",
    "            else:\n",
    "                self._pfos_init = True\n",
    "                this_mask = self.get_curr_mask()\n",
    "                self._init_pfo_count = ak.count(this_mask)\n",
    "                last_remaining = ak.sum(self._init_pfo_count)\n",
    "        else:\n",
    "            last_remaining = self._table_data[\"Remaining PFOs\"][-1]\n",
    "        if this_sig[1] == -1:\n",
    "            this_mask = self.get_curr_mask()\n",
    "            curr_remaining = ak.sum(self._last_pfo_counts[this_mask])\n",
    "            curr_events_remaining = ak.sum(this_mask)\n",
    "            return [\n",
    "                curr_remaining,\n",
    "                0.,\n",
    "                100.,\n",
    "                curr_remaining/curr_events_remaining]\n",
    "        else:\n",
    "            this_mask = self.get_curr_mask()\n",
    "            self._last_pfo_counts = ak.count(this_mask, axis=1)\n",
    "            curr_remaining = ak.sum(this_mask)\n",
    "            curr_events_remaining = ak.num(this_mask, axis=0)\n",
    "        return [curr_remaining,\n",
    "                100 * curr_remaining/self._init_pfo_count,\n",
    "                100 * curr_remaining/last_remaining,\n",
    "                curr_remaining/curr_events_remaining]\n",
    "\n",
    "    def _append_table_data(self, data):\n",
    "        for i in range(len(self._pfo_table_cols)):\n",
    "            self._table_data[self._pfo_table_cols[i]].append(data[i])\n",
    "        return\n",
    "    \n",
    "    def _update_table_data(self, name):\n",
    "        table_data = [name]\n",
    "        table_data += self._get_remaining_events_data()\n",
    "        table_data += self._get_remaining_pfos_data()\n",
    "        self._append_table_data(table_data)\n",
    "        self._concat_indicies[-1] += 1\n",
    "        return\n",
    "\n",
    "    def concatenate(self, other, return_copy=False):\n",
    "        if not isinstance(other, CutHandler):\n",
    "            raise NotImplementedError(\"CutHandler object can only be added to another CutHandler object\")\n",
    "        # Make sure the new set is consequtive\n",
    "        if self._check_signature(other._signatures[0]) and (other._signatures[0][1] != -1):\n",
    "            raise ValueError(f\"Combining CutHandler objects requires consequtively matching signatures: \"\n",
    "                             + f\"{self._end_sig} and {other._signatures[0]} do not match.\")\n",
    "        if return_copy:\n",
    "            result = self.copy()\n",
    "        else:\n",
    "            result = self\n",
    "        result._empty_curr_mask_queue()\n",
    "        result._conseq_masks += other._conseq_masks\n",
    "        result._curr_masks = other._curr_masks\n",
    "        result._signatures += other._signatures[1:]\n",
    "        result._start_sig = other._start_sig\n",
    "        result.concat_index += 1\n",
    "        result._concat_indicies += [i + len(result._concat_indicies) for i in other._concat_indicies]\n",
    "        renormed_data = result._change_table_data_init_count(\n",
    "            other,\n",
    "            result._table_data[\"Remaining events\"][0],\n",
    "            result._init_pfo_count,\n",
    "            last_pfos_count=result._last_pfo_counts)\n",
    "        result._pfos_init |= other._pfos_init\n",
    "        result._last_pfo_counts = other._last_pfo_counts\n",
    "        for c in result._pfo_table_cols:\n",
    "            result._table_data[c] += renormed_data[c][1:]\n",
    "        if return_copy:\n",
    "            return result\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self.concatenate(other, return_copy=True)\n",
    "\n",
    "    def _change_table_data_init_count(\n",
    "            self, cut_obj,\n",
    "            new_init_evts, new_init_pfos,\n",
    "            last_events=None, last_pfos_count=None):\n",
    "        new_data = cut_obj._table_data.copy()\n",
    "        evt_counts = new_data[\"Remaining events\"]\n",
    "        new_evts_full = [100 * c/new_init_evts for c in evt_counts]\n",
    "        new_evts_rel = new_data[\"Relative percentage events\"]\n",
    "        if last_events is not None:\n",
    "            new_evts_rel[0] = 100 * evt_counts[0]/last_events\n",
    "        pfo_counts = new_data[\"Remaining PFOs\"]\n",
    "        recreate_pfo_data = False\n",
    "        if new_init_pfos != \"-\":\n",
    "            if \"-\" not in pfo_counts:\n",
    "                new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\n",
    "            else:\n",
    "                # Need to add thing to catch case of second item being events based\n",
    "                if last_pfos_count is not None:\n",
    "                    recreate_pfo_data = True\n",
    "                    counts_to_use = [np.sum(last_pfos_count[mask]) for mask in cut_obj._pre_pfo_init_masks]\n",
    "                    counts_to_use += pfo_counts[1+len(counts_to_use):]\n",
    "                    counts_to_use = [np.sum(last_pfos_count)] + counts_to_use\n",
    "                    pfo_counts = counts_to_use\n",
    "                    new_pfos_full = [100 * c/new_init_pfos for c in pfo_counts]\n",
    "                else:\n",
    "                    new_pfos_full = new_data[\"Percentage of total PFOs remaining\"]\n",
    "        else:\n",
    "            new_pfos_full = new_data[\"Remaining PFOs\"]\n",
    "        if recreate_pfo_data:\n",
    "            new_pfos_rel = [100.] + [100 * this/last for this, last in zip(counts_to_use[1:], counts_to_use[:-1])]\n",
    "        else:\n",
    "            new_pfos_rel = new_data[\"Relative percentage of PFOs\"]\n",
    "        if last_pfos_count is not None:\n",
    "            new_pfos_rel[0] = 100 * pfo_counts/np.sum(last_pfos_count)\n",
    "        if recreate_pfo_data:\n",
    "            new_ave_pfos = [pfos/evts for pfos, evts in zip(evt_counts, pfo_counts)]\n",
    "        else:\n",
    "            new_ave_pfos = new_data[\"Average PFOs per event\"]\n",
    "        return {\n",
    "            \"Name\":new_data[\"Name\"],\n",
    "            \"Remaining events\":evt_counts,\n",
    "            \"Percentage of total events remaining\":new_evts_full,\n",
    "            \"Relative percentage events\":new_evts_rel,\n",
    "            \"Remaining PFOs\":pfo_counts,\n",
    "            \"Percentage of total PFOs remaining\":new_pfos_full,\n",
    "            \"Relative percentage of PFOs\":new_pfos_rel,\n",
    "            \"Average PFOs per event\":new_ave_pfos}\n",
    "\n",
    "    def _empty_curr_mask_queue(self):\n",
    "        result = self._curr_masks[0]\n",
    "        for m in self._curr_masks[1:]:\n",
    "            result = result * m\n",
    "        self._conseq_masks += [result]\n",
    "        self._curr_masks = []\n",
    "        return\n",
    "\n",
    "    def add_mask(self, mask, name):\n",
    "        # TODO need to decide if the mask needs to be stored separately:\n",
    "        # This is needed if PFO is not set, and we are in an events-like (and simultaneous like, but probably ignore that for ease) signature\n",
    "        this_sig = self._get_mask_signature(mask)\n",
    "        if len(self._curr_masks) == 0 and len(self._conseq_masks) == 0:\n",
    "            self._add_initial_data(mask)\n",
    "        elif not self._check_signature(this_sig):\n",
    "            self._empty_curr_mask_queue()\n",
    "        self._curr_masks += [mask]\n",
    "        # else:\n",
    "            # If signature matches previous init signature, then add to self._curr_masks\n",
    "            # Else if it matches the end signature, put the current mask into self._conseq_masks\n",
    "            #   Reset current masks back to []\n",
    "            # curr_sig = self._get_mask_signature(mask)\n",
    "            # if len(self._curr_masks) == 1:\n",
    "            #     # self._consequtive stores the initial state of\n",
    "            #     # the first mask until set as a boolean here\n",
    "            #     consequtive = curr_sig == self._consequtive\n",
    "            #     if consequtive:\n",
    "            #         self._signature = self._consequtive\n",
    "            #     self._consequtive = consequtive\n",
    "            # self._validate_signature(curr_sig)\n",
    "            # if self._consequtive:\n",
    "            #     self._signature = self._get_mask_signature(mask, end=True)\n",
    "        self._signatures += [self._get_mask_signature(mask, end=True)]\n",
    "        self._get_mask_signature(mask, update=True)\n",
    "        self._update_table_data(name)\n",
    "        return\n",
    "        \n",
    "    def get_curr_mask(self):\n",
    "        if len(self._curr_masks) == 0:\n",
    "            if len(self._conseq_masks) == 0:\n",
    "                raise IndexError(\"No masks added\")\n",
    "            return self._conseq_masks[-1]\n",
    "        result = self._curr_masks[0]\n",
    "        for m in self._curr_masks[1:]:\n",
    "            result = result * m\n",
    "        return result\n",
    "        # if len(self._curr_masks) == 0:\n",
    "        #     raise IndexError(\"No masks added\")\n",
    "        # if self._consequtive:\n",
    "        #     # N.B. also entered if only 1 mask is added\n",
    "        #     # TODO this doesn't work! mask signature needs to be the initial signature still\n",
    "        #     res = self._curr_masks[0]\n",
    "        #     for mask in self._curr_masks[1:]:\n",
    "        #         res = res[mask]\n",
    "        # else:\n",
    "        #     event_masks = []\n",
    "        #     pfo_masks = []\n",
    "        #     if not self._pfos_init:\n",
    "        #         res = self._combine_masks(self._curr_masks)\n",
    "        #     else:\n",
    "        #         for i, sig in enumerate(self._signatures):\n",
    "        #             if sig[1] == -1:\n",
    "        #                 event_masks += [self._curr_masks[i]]\n",
    "        #             else:\n",
    "        #                 pfo_masks += [self._curr_masks[i]]\n",
    "        #         event_mask = self._combine_masks(event_masks)\n",
    "        #         res = self._combine_masks(pfo_masks)\n",
    "        #         if event_mask is not None:\n",
    "        #             res = event_mask * res\n",
    "        # return res\n",
    "\n",
    "    def apply_masks(self, data, return_table=False, application_index=0):\n",
    "        result = data\n",
    "        for m in self._conseq_masks[application_index:]:\n",
    "            result = result[m]\n",
    "        result = result[self.get_curr_mask()]\n",
    "        if return_table:\n",
    "            return result, self.get_table()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def get_table(self, initial_concat_index=0, initial_name=\"Initial data\", events_only=False):\n",
    "        data = self._table_data\n",
    "        if initial_concat_index > self.concat_index:\n",
    "            raise IndexError(\n",
    "                f\"Concatenation index {initial_concat_index} out of range, \"\n",
    "                + f\"only {self.concat_index} concatenation(s) present.\")\n",
    "        if initial_concat_index > 0:\n",
    "            start_event_index = self._concat_indicies[initial_concat_index]\n",
    "            data = self._change_table_data_init_count(\n",
    "                self,\n",
    "                data[\"Remaining events\"][start_event_index],\n",
    "                data[\"Remaining PFOs\"][start_event_index])\n",
    "            data[\"Name\"][0] = initial_name\n",
    "        if events_only:\n",
    "            return pd.DataFrame({key:data[key] for key in self._event_table_cols})\n",
    "        else:\n",
    "            return pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 8, 9, 7, 9], [9, 6, 1], [3, 9], [4, 7, ... [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n",
      "[[False, True, True, True, True], [True, True, ... [True, True, False], [True, True]]\n",
      "[[True, False, False, False, False], [False, ... [True, True, True], [False, True]]\n",
      "[[False, True, True, True, True], [True, True, ... [True, True, False], [True, True]]\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "test_data = np.random.randint(0, 10, size=size)\n",
    "curr_i = 0\n",
    "data = []\n",
    "while curr_i < size:\n",
    "    this_size = np.random.randint(0,6)\n",
    "    data += [test_data[curr_i:min(curr_i + this_size, size)]]\n",
    "    curr_i += this_size\n",
    "data = ak.Array(data)\n",
    "print(data)\n",
    "mask_1 = data > 2\n",
    "print(mask_1)\n",
    "mask_2 = data < 7\n",
    "print(mask_2)\n",
    "mask_3 = data >=4\n",
    "print(mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "No masks added",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cutter_num \u001b[39m=\u001b[39m CutHandler()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m cutter_num\u001b[39m.\u001b[39;49mget_curr_mask()\n",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 17\u001b[0m in \u001b[0;36mCutHandler.get_curr_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=298'>299</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_curr_masks) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=299'>300</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conseq_masks) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=300'>301</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo masks added\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=301'>302</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conseq_masks[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=302'>303</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_curr_masks[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: No masks added"
     ]
    }
   ],
   "source": [
    "cutter_num = CutHandler()\n",
    "cutter_num.get_curr_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False, True, True, True, True], [True, True, ... [True, True, False], [True, True]]\n",
      "1 done\n",
      "[[False, False, False, False, False], [False, ... [True, True, False], [False, True]]\n",
      "2 done\n",
      "[[False, False, False, False, False], [False, ... [True, True, False], [False, True]]\n",
      "3 done\n",
      "[[], [6], [], [4], [6], [6], [], [], [5, ... [], [5, 6], [], [], [], [], [4, 5], [4]]\n",
      "(429, 1000)\n",
      "(429, 301)\n"
     ]
    }
   ],
   "source": [
    "cutter_num.add_mask(mask_1, \">2\")\n",
    "print(cutter_num.get_curr_mask())\n",
    "print(\"1 done\")\n",
    "cutter_num.add_mask(mask_2, \"<7\")\n",
    "print(cutter_num.get_curr_mask())\n",
    "print(\"2 done\")\n",
    "cutter_num.add_mask(mask_3, \">=4\")\n",
    "print(cutter_num.get_curr_mask())\n",
    "print(\"3 done\")\n",
    "print(data[cutter_num.get_curr_mask()])\n",
    "print(cutter_num._get_mask_signature(data))\n",
    "print(cutter_num._get_mask_signature(data[cutter_num.get_curr_mask()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [6], [], [4], [6], [6], [], [], [5, ... [], [5, 6], [], [], [], [], [4, 5], [4]]\n",
      "[[], [6], [], [4], [6], [6], [], [], [5, ... [], [5, 6], [], [], [], [], [4, 5], [4]]\n",
      "[[1, 8, 9, 7, 9], [9, 6, 1], [3, 9], [4, 7, ... [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.331002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>685</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>1.596737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>394</td>\n",
       "      <td>39.4</td>\n",
       "      <td>57.518248</td>\n",
       "      <td>0.918415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>301</td>\n",
       "      <td>30.1</td>\n",
       "      <td>76.395939</td>\n",
       "      <td>0.701632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data               429                                 100.0   \n",
       "1            >2               429                                 100.0   \n",
       "2            <7               429                                 100.0   \n",
       "3           >=4               429                                 100.0   \n",
       "\n",
       "   Relative percentage events  Remaining PFOs  \\\n",
       "0                       100.0            1000   \n",
       "1                       100.0             685   \n",
       "2                       100.0             394   \n",
       "3                       100.0             301   \n",
       "\n",
       "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
       "0                               100.0                   100.000000   \n",
       "1                                68.5                    68.500000   \n",
       "2                                39.4                    57.518248   \n",
       "3                                30.1                    76.395939   \n",
       "\n",
       "   Average PFOs per event  \n",
       "0                2.331002  \n",
       "1                1.596737  \n",
       "2                0.918415  \n",
       "3                0.701632  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cutter_num.apply_masks(data))\n",
    "print(data[cutter_num.get_curr_mask()])\n",
    "print(data)\n",
    "cutter_num.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data               429                                 100.0   \n",
       "1            >2               429                                 100.0   \n",
       "2            <7               429                                 100.0   \n",
       "3           >=4               429                                 100.0   \n",
       "\n",
       "   Relative percentage events  \n",
       "0                       100.0  \n",
       "1                       100.0  \n",
       "2                       100.0  \n",
       "3                       100.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter_num.get_table(events_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Concatenation index 1 out of range, only 0 concatenation(s) present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cutter_num\u001b[39m.\u001b[39;49mget_table(initial_concat_index\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 21\u001b[0m in \u001b[0;36mCutHandler.get_table\u001b[0;34m(self, initial_concat_index, initial_name, events_only)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=342'>343</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table_data\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=343'>344</a>\u001b[0m \u001b[39mif\u001b[39;00m initial_concat_index \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat_index:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=344'>345</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=345'>346</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConcatenation index \u001b[39m\u001b[39m{\u001b[39;00minitial_concat_index\u001b[39m}\u001b[39;00m\u001b[39m out of range, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=346'>347</a>\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat_index\u001b[39m}\u001b[39;00m\u001b[39m concatenation(s) present.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=347'>348</a>\u001b[0m \u001b[39mif\u001b[39;00m initial_concat_index \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=348'>349</a>\u001b[0m     start_event_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concat_indicies[initial_concat_index]\n",
      "\u001b[0;31mIndexError\u001b[0m: Concatenation index 1 out of range, only 0 concatenation(s) present."
     ]
    }
   ],
   "source": [
    "cutter_num.get_table(initial_concat_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_initial_data',\n",
       " '_append_table_data',\n",
       " '_change_table_data_init_count',\n",
       " '_check_signature',\n",
       " '_concat_indicies',\n",
       " '_conseq_masks',\n",
       " '_curr_masks',\n",
       " '_empty_curr_mask_queue',\n",
       " '_end_sig',\n",
       " '_event_inds_indicies',\n",
       " '_event_table_cols',\n",
       " '_get_last_pfo_sig',\n",
       " '_get_mask_signature',\n",
       " '_get_remaining_events_data',\n",
       " '_get_remaining_pfos_data',\n",
       " '_init_pfo_count',\n",
       " '_last_pfo_counts',\n",
       " '_pfo_table_cols',\n",
       " '_pfos_init',\n",
       " '_signatures',\n",
       " '_start_sig',\n",
       " '_table_data',\n",
       " '_update_table_data',\n",
       " 'add_mask',\n",
       " 'apply_masks',\n",
       " 'concat_index',\n",
       " 'concatenate',\n",
       " 'copy',\n",
       " 'get_curr_mask',\n",
       " 'get_table']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cutter_num)\n",
    "['add_mask',\n",
    " 'apply_masks',\n",
    " 'concat_index',\n",
    " 'concatenate',\n",
    " 'copy',\n",
    " 'get_curr_mask',\n",
    " 'get_table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, False, ... True, True, True, True, True, True]\n",
      "[False, True, True, True, True, False, True, ... True, True, True, True, True, True]\n",
      "[True, True, True, True, True, True, False, ... True, True, True, True, True, True]\n",
      "1 done\n",
      "[False, True, True, True, True, False, False, ... True, True, True, True, True, True]\n",
      "2 done\n",
      "[[9, 6, 1], [3, 9], [4, 7, 7], [6], [5], ... 8], [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n",
      "(429, 1000)\n",
      "(228, 450)\n",
      "[[9, 6, 1], [3, 9], [4, 7, 7], [6], [5], ... 8], [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n",
      "[[9, 6, 1], [3, 9], [4, 7, 7], [6], [5], ... 8], [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n",
      "[[1, 8, 9, 7, 9], [9, 6, 1], [3, 9], [4, 7, ... [2, 9, 9], [2], [4, 5, 1], [9, 4]]\n",
      "                  Name  Remaining events  \\\n",
      "0         Initial data               429   \n",
      "1             No empty               351   \n",
      "2   At most 3 in event               228   \n",
      "\n",
      "   Percentage of total events remaining  Relative percentage events  \\\n",
      "0                            100.000000                  100.000000   \n",
      "1                             81.818182                   81.818182   \n",
      "2                             53.146853                   64.957265   \n",
      "\n",
      "  Remaining PFOs Percentage of total PFOs remaining  \\\n",
      "0   Not supplied                                  -   \n",
      "1              -                                  -   \n",
      "2              -                                  -   \n",
      "\n",
      "  Relative percentage of PFOs Average PFOs per event  \n",
      "0                           -                      -  \n",
      "1                           -                      -  \n",
      "2                           -                      -  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No empty</td>\n",
       "      <td>351</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At most 3 in event</td>\n",
       "      <td>228</td>\n",
       "      <td>53.146853</td>\n",
       "      <td>64.957265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  Remaining events  \\\n",
       "0         Initial data               429   \n",
       "1             No empty               351   \n",
       "2   At most 3 in event               228   \n",
       "\n",
       "   Percentage of total events remaining  Relative percentage events  \n",
       "0                            100.000000                  100.000000  \n",
       "1                             81.818182                   81.818182  \n",
       "2                             53.146853                   64.957265  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts_cutter = CutHandler()\n",
    "evt_1 = ak.num(data, axis=1) > 0\n",
    "print(evt_1)\n",
    "evt_2 = ak.num(data, axis=1) <= 3\n",
    "print(evt_2)\n",
    "evts_cutter.add_mask(evt_1, \"No empty\")\n",
    "print(evts_cutter.get_curr_mask())\n",
    "print(\"1 done\")\n",
    "evts_cutter.add_mask(evt_2, \" At most 3 in event\")\n",
    "print(evts_cutter.get_curr_mask())\n",
    "print(\"2 done\")\n",
    "print(data[evts_cutter.get_curr_mask()])\n",
    "print(evts_cutter._get_mask_signature(data))\n",
    "print(evts_cutter._get_mask_signature(evts_cutter.apply_masks(data)))\n",
    "print(evts_cutter.apply_masks(data))\n",
    "print(data[evts_cutter.get_curr_mask()])\n",
    "print(data)\n",
    "print(evts_cutter.get_table())\n",
    "evts_cutter.get_table(events_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No empty</td>\n",
       "      <td>351</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At most 3 in event</td>\n",
       "      <td>228</td>\n",
       "      <td>53.146853</td>\n",
       "      <td>64.957265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  Remaining events  \\\n",
       "0         Initial data               429   \n",
       "1             No empty               351   \n",
       "2   At most 3 in event               228   \n",
       "\n",
       "   Percentage of total events remaining  Relative percentage events  \n",
       "0                            100.000000                  100.000000  \n",
       "1                             81.818182                   81.818182  \n",
       "2                             53.146853                   64.957265  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts_cutter.get_table(events_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.331002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>685</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>1.596737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>394</td>\n",
       "      <td>39.4</td>\n",
       "      <td>57.518248</td>\n",
       "      <td>0.918415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>301</td>\n",
       "      <td>30.1</td>\n",
       "      <td>76.395939</td>\n",
       "      <td>0.701632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data               429                                 100.0   \n",
       "1            >2               429                                 100.0   \n",
       "2            <7               429                                 100.0   \n",
       "3           >=4               429                                 100.0   \n",
       "\n",
       "   Relative percentage events  Remaining PFOs  \\\n",
       "0                       100.0            1000   \n",
       "1                       100.0             685   \n",
       "2                       100.0             394   \n",
       "3                       100.0             301   \n",
       "\n",
       "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
       "0                               100.0                   100.000000   \n",
       "1                                68.5                    68.500000   \n",
       "2                                39.4                    57.518248   \n",
       "3                                30.1                    76.395939   \n",
       "\n",
       "   Average PFOs per event  \n",
       "0                2.331002  \n",
       "1                1.596737  \n",
       "2                0.918415  \n",
       "3                0.701632  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter_num.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Initial data', '>2', '<7', '>=4', 'No empty', ' At most 3 in event']\n",
      "[429, 429, 429, 429, 351, 228]\n",
      "[100.0, 100.0, 100.0, 100.0, 81.81818181818181, 53.14685314685315]\n",
      "[100.0, 100.0, 100.0, 100.0, 81.81818181818181, 64.95726495726495]\n",
      "[1000, 685, 394, 301, 1000, 450]\n",
      "[100.0, 68.5, 39.4, 30.1, 100.0, 45.0]\n",
      "[100.0, 68.5, 57.518248175182485, 76.39593908629442, 100.0, 45.0]\n",
      "[2.331002331002331, 1.5967365967365967, 0.9184149184149184, 0.7016317016317016, 0.351, 0.5066666666666667]\n"
     ]
    }
   ],
   "source": [
    "comb_cuts = cutter_num + evts_cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CutHandler'>\n",
      "True\n",
      "<class '__main__.CutHandler'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(cutter_num.copy()))\n",
    "print(isinstance(cutter_num.copy(), CutHandler))\n",
    "print(type(evts_cutter.copy()))\n",
    "print(isinstance(evts_cutter.copy(), CutHandler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['Initial data', '>2', '<7', '>=4', 'No empty', ' At most 3 in event']\n",
      "[429, 429, 429, 429, 351, 228]\n",
      "[100.0, 100.0, 100.0, 100.0, 81.81818181818181, 53.14685314685315]\n",
      "[100.0, 100.0, 100.0, 100.0, 81.81818181818181, 64.95726495726495]\n",
      "[1000, 685, 394, 301, 1000, 450]\n",
      "[100.0, 68.5, 39.4, 30.1, 100.0, 45.0]\n",
      "[100.0, 68.5, 57.518248175182485, 76.39593908629442, 100.0, 45.0]\n",
      "[2.331002331002331, 1.5967365967365967, 0.9184149184149184, 0.7016317016317016, 0.351, 0.5066666666666667]\n"
     ]
    }
   ],
   "source": [
    "x = cutter_num.copy()\n",
    "print(isinstance(x, CutHandler))\n",
    "x.concatenate(evts_cutter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.331002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>685</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>1.596737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>394</td>\n",
       "      <td>39.4</td>\n",
       "      <td>57.518248</td>\n",
       "      <td>0.918415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>301</td>\n",
       "      <td>30.1</td>\n",
       "      <td>76.395939</td>\n",
       "      <td>0.701632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No empty</td>\n",
       "      <td>351</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>At most 3 in event</td>\n",
       "      <td>228</td>\n",
       "      <td>53.146853</td>\n",
       "      <td>64.957265</td>\n",
       "      <td>450</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  Remaining events  \\\n",
       "0         Initial data               429   \n",
       "1                   >2               429   \n",
       "2                   <7               429   \n",
       "3                  >=4               429   \n",
       "4             No empty               351   \n",
       "5   At most 3 in event               228   \n",
       "\n",
       "   Percentage of total events remaining  Relative percentage events  \\\n",
       "0                            100.000000                  100.000000   \n",
       "1                            100.000000                  100.000000   \n",
       "2                            100.000000                  100.000000   \n",
       "3                            100.000000                  100.000000   \n",
       "4                             81.818182                   81.818182   \n",
       "5                             53.146853                   64.957265   \n",
       "\n",
       "   Remaining PFOs  Percentage of total PFOs remaining  \\\n",
       "0            1000                               100.0   \n",
       "1             685                                68.5   \n",
       "2             394                                39.4   \n",
       "3             301                                30.1   \n",
       "4            1000                               100.0   \n",
       "5             450                                45.0   \n",
       "\n",
       "   Relative percentage of PFOs  Average PFOs per event  \n",
       "0                   100.000000                2.331002  \n",
       "1                    68.500000                1.596737  \n",
       "2                    57.518248                0.918415  \n",
       "3                    76.395939                0.701632  \n",
       "4                   100.000000                0.351000  \n",
       "5                    45.000000                0.506667  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.331002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>685</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>1.596737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>394</td>\n",
       "      <td>39.4</td>\n",
       "      <td>57.518248</td>\n",
       "      <td>0.918415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>301</td>\n",
       "      <td>30.1</td>\n",
       "      <td>76.395939</td>\n",
       "      <td>0.701632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data               429                                 100.0   \n",
       "1            >2               429                                 100.0   \n",
       "2            <7               429                                 100.0   \n",
       "3           >=4               429                                 100.0   \n",
       "\n",
       "   Relative percentage events  Remaining PFOs  \\\n",
       "0                       100.0            1000   \n",
       "1                       100.0             685   \n",
       "2                       100.0             394   \n",
       "3                       100.0             301   \n",
       "\n",
       "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
       "0                               100.0                   100.000000   \n",
       "1                                68.5                    68.500000   \n",
       "2                                39.4                    57.518248   \n",
       "3                                30.1                    76.395939   \n",
       "\n",
       "   Average PFOs per event  \n",
       "0                2.331002  \n",
       "1                1.596737  \n",
       "2                0.918415  \n",
       "3                0.701632  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter_num.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Not supplied</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No empty</td>\n",
       "      <td>351</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At most 3 in event</td>\n",
       "      <td>228</td>\n",
       "      <td>53.146853</td>\n",
       "      <td>64.957265</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  Remaining events  \\\n",
       "0         Initial data               429   \n",
       "1             No empty               351   \n",
       "2   At most 3 in event               228   \n",
       "\n",
       "   Percentage of total events remaining  Relative percentage events  \\\n",
       "0                            100.000000                  100.000000   \n",
       "1                             81.818182                   81.818182   \n",
       "2                             53.146853                   64.957265   \n",
       "\n",
       "  Remaining PFOs Percentage of total PFOs remaining  \\\n",
       "0   Not supplied                                  -   \n",
       "1              -                                  -   \n",
       "2              -                                  -   \n",
       "\n",
       "  Relative percentage of PFOs Average PFOs per event  \n",
       "0                           -                      -  \n",
       "1                           -                      -  \n",
       "2                           -                      -  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts_cutter.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Remaining events</th>\n",
       "      <th>Percentage of total events remaining</th>\n",
       "      <th>Relative percentage events</th>\n",
       "      <th>Remaining PFOs</th>\n",
       "      <th>Percentage of total PFOs remaining</th>\n",
       "      <th>Relative percentage of PFOs</th>\n",
       "      <th>Average PFOs per event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial data</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.331002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;2</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>685</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>1.596737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;7</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>394</td>\n",
       "      <td>39.4</td>\n",
       "      <td>57.518248</td>\n",
       "      <td>0.918415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;=4</td>\n",
       "      <td>429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>301</td>\n",
       "      <td>30.1</td>\n",
       "      <td>76.395939</td>\n",
       "      <td>0.701632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Remaining events  Percentage of total events remaining  \\\n",
       "0  Initial data               429                                 100.0   \n",
       "1            >2               429                                 100.0   \n",
       "2            <7               429                                 100.0   \n",
       "3           >=4               429                                 100.0   \n",
       "\n",
       "   Relative percentage events  Remaining PFOs  \\\n",
       "0                       100.0            1000   \n",
       "1                       100.0             685   \n",
       "2                       100.0             394   \n",
       "3                       100.0             301   \n",
       "\n",
       "   Percentage of total PFOs remaining  Relative percentage of PFOs  \\\n",
       "0                               100.0                   100.000000   \n",
       "1                                68.5                    68.500000   \n",
       "2                                39.4                    57.518248   \n",
       "3                                30.1                    76.395939   \n",
       "\n",
       "   Average PFOs per event  \n",
       "0                2.331002  \n",
       "1                1.596737  \n",
       "2                0.918415  \n",
       "3                0.701632  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 688)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutter2 = CutHandler()\n",
    "small_data = data[evt_1][evt_2]\n",
    "print(small_data)\n",
    "smask_1 = small_data > 2\n",
    "print(smask_1)\n",
    "smask_2 = small_data < 7\n",
    "print(smask_2)\n",
    "smask_3 = small_data >=4\n",
    "print(smask_3)\n",
    "evts_cutter.add_mask(evt_1, \"No empty\")\n",
    "print(evts_cutter.get_curr_mask())\n",
    "print(\"1 done\")\n",
    "evts_cutter.add_mask(evt_2, \" At most 3 in event\")\n",
    "print(evts_cutter.get_curr_mask())\n",
    "print(\"2 done\")\n",
    "print(data[evts_cutter.get_curr_mask()])\n",
    "print(evts_cutter._get_mask_signature(data))\n",
    "print(evts_cutter._get_mask_signature(evts_cutter.apply_masks(data)))\n",
    "print(evts_cutter.apply_masks(data))\n",
    "print(data[evts_cutter.get_curr_mask()])\n",
    "print(data)\n",
    "print(evts_cutter.get_table())\n",
    "evts_cutter.get_table(events_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NotImplementedError'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NotImplementedError' object has no attribute 'get_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(comb_cuts))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22736330314e6f56504e227d/users/wx21978/projects/pion-phys/pi0-analysis/analysis/notebooks/cuthandler_tests.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m comb_cuts\u001b[39m.\u001b[39;49mget_table()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NotImplementedError' object has no attribute 'get_table'"
     ]
    }
   ],
   "source": [
    "print(type(comb_cuts))\n",
    "comb_cuts.get_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 30)\n",
      "(11, 19)\n",
      "(16, 30)\n",
      "(13, 21)\n",
      "(16, 30)\n",
      "(9, 14)\n"
     ]
    }
   ],
   "source": [
    "print(cutter_num._get_mask_signature(mask_1))\n",
    "print(cutter_num._get_mask_signature(mask_1, end=True))\n",
    "print(cutter_num._get_mask_signature(mask_2))\n",
    "print(cutter_num._get_mask_signature(mask_2, end=True))\n",
    "print(cutter_num._get_mask_signature(mask_3))\n",
    "print(cutter_num._get_mask_signature(mask_3, end=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ak.sum(ak.any(mask_1, axis=1)), ak.sum(mask_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[True], [True, ... [False, True]] type='16 * var * bool'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.any(mask_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[[True]], ... [[False, True]]] type='16 * var * var * bool'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi0-phys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab5cce96a7a9ac3fdc711af02157968a1581b13a22b1847cb342392bac05bbf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
