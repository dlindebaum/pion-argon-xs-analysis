{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(1, '/users/wx21978/projects/pion-phys/pi0-analysis/analysis/')\n",
    "import os\n",
    "from importlib import reload\n",
    "import copy\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_gnn as tfgnn\n",
    "# from tensorflow_gnn.models import gat_v2\n",
    "# from tensorflow import keras\n",
    "# import sklearn.ensemble as ensemble\n",
    "# import sklearn.impute as impute\n",
    "import awkward as ak\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as plt_colours\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits import mplot3d\n",
    "# import matplotlib as mpl\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from python.analysis import EventSelection, Plots, vector, PairSelection, Master, PFOSelection, cross_section, CutOptimization\n",
    "from particle import Particle\n",
    "from python.analysis import Plots, Master, cross_section, AnalysisInputs, Slicing, EnergyTools, Utils\n",
    "import apps.cex_analysis_input as cai\n",
    "import apps.cex_beam_selection_studies as cbs\n",
    "import apps.cex_gnn_predictions as cgp\n",
    "from python.analysis import SelectionEvaluation as seval\n",
    "from iminuit import cost, Minuit\n",
    "import scipy.stats as scistats\n",
    "from python.gnn import DataPreparation, Models, bdt_classifier, Layers, Fitter\n",
    "# import apps.cex_analysis_input as cai\n",
    "from apps import photon_pairs\n",
    "from scipy.stats import poisson, rv_histogram\n",
    "import scipy.optimize as opt\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_conf = Plots.PlotConfig()\n",
    "plt_conf.SHOW_PLOT = True\n",
    "plt_conf.SAVE_FOLDER = None\n",
    "# plt_conf.BINS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = cross_section.ApplicationArguments.ResolveConfig(cross_section.LoadConfiguration(\n",
    "    \"/users/wx21978/projects/pion-phys/analyses/3GeV_actual_asimov/config_3GeV_MC_actual_asimov.json\"))\n",
    "    # \"/users/wx21978/projects/pion-phys/analyses/3Gev_Asimov/config_3GeV_MC_asimov.json\"))\n",
    "\n",
    "ai_template = cai.load_analysis_input(args, True)\n",
    "ai_data = cai.load_analysis_input(args, False)\n",
    "\n",
    "evts_mc_1 = Master.Data(args.ntuple_files[\"mc\"][1][\"file\"], nTuple_type=args.ntuple_files[\"mc\"][1][\"type\"], target_momentum=args.ntuple_files[\"mc\"][1][\"pmom\"])\n",
    "evts_mc_1 = cbs.BeamPionSelection(evts_mc_1, args, True)\n",
    "# ai_template = cai.get_analysis_input(evts_mc_1, args, True)\n",
    "\n",
    "evts_mc_2 = Master.Data(args.ntuple_files[\"mc\"][2][\"file\"], nTuple_type=args.ntuple_files[\"mc\"][2][\"type\"], target_momentum=args.ntuple_files[\"mc\"][2][\"pmom\"])\n",
    "evts_mc_2 = cbs.BeamPionSelection(evts_mc_2, args, True)\n",
    "# ai_data = cai.get_analysis_input(evts_mc_2, args, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ai_data.KE_int_reco, bins=30, range=(1700, 3400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ai_data.KE_int_reco, bins=30, range=(1700, 3400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_int_reco, ai_template.KE_int_true, bins=np.linspace(1800, 3300, 30), norm=\"log\")\n",
    "plt.colorbar()\n",
    "for edge in args.energy_slices.pos:\n",
    "    plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "plt_conf.format_axis(xlabel=\"Reco energy\", ylabel=\"True energy\")\n",
    "plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_int_true, ai_template.KE_init_true, bins=[np.linspace(1800, 3300, 60), np.linspace(2200, 3500, 60)], norm=\"log\")\n",
    "plt.colorbar()\n",
    "# for edge in args.energy_slices.pos:\n",
    "#     plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "#     plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "plt_conf.format_axis(xlabel=\"Interaction energy\", ylabel=\"Initial energy\")\n",
    "plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_int_reco, ai_template.KE_init_reco, bins=[np.linspace(1800, 3300, 60), np.linspace(2200, 3500, 60)], norm=\"log\")\n",
    "plt.colorbar()\n",
    "# for edge in args.energy_slices.pos:\n",
    "#     plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "#     plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "plt_conf.format_axis(xlabel=\"Interaction energy\", ylabel=\"Initial energy\")\n",
    "plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices(3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bin_pos=np.array([3300, 2950, 2790, 2700, 2500, 2000])\n",
    "counts_in_bins = []\n",
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_init_reco, ai_template.KE_int_reco, bins=np.linspace(1800, 3500, 60), norm=\"log\")\n",
    "plt.colorbar()\n",
    "# for edge in test_bin_pos:\n",
    "#     plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "#     plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "# for i, (high, low) in enumerate(zip(test_bin_pos[:-1], test_bin_pos[1:])):\n",
    "#     plt.fill(np.array([low, high, high, low]), np.array([low, low, high, high]), \"black\", alpha=0.3)\n",
    "    # entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "    # plt.fill(np.array([high, 10000, 10000, high]), np.array([low, low, high, high]), entry_col, alpha=0.2)\n",
    "    # counts_in_bins.append(np.sum(np.logical_and(\n",
    "    #     np.logical_and(\n",
    "    #         ai_template.KE_int_reco <= high,\n",
    "    #         ai_template.KE_int_reco > low),\n",
    "    #     ai_template.KE_init_reco > high)))\n",
    "plt_conf.format_axis(xlabel=\"Initial energy\", ylabel=\"Interaction energy\")\n",
    "plt_conf.end_plot()\n",
    "print(test_bin_pos)\n",
    "print(counts_in_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_e_binning(bin_edges, analysis_input, reco=True, plt_conf=None, plt_bins=60, lower=1800, upper=3500):\n",
    "    ke_init = analysis_input.KE_init_reco if reco else analysis_input.KE_init_true\n",
    "    ke_int = analysis_input.KE_int_reco if reco else analysis_input.KE_int_true\n",
    "    if plt_conf is None:\n",
    "        plt_conf = Plots.PlotConfig()\n",
    "        plt_conf.SHOW_PLOT = True\n",
    "        plt_conf.SAVE_FOLDER = None\n",
    "    counts_in_bins = []\n",
    "    plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "    plt.hist2d(ke_init, ke_int,\n",
    "               bins=np.linspace(lower, upper, plt_bins), norm=\"log\")\n",
    "    plt.colorbar()\n",
    "    for edge in bin_edges:\n",
    "        plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "        plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    for i, (high, low) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        plt.fill(np.array([low, high, high, low]), np.array([low, low, high, high]), \"black\", alpha=0.3)\n",
    "        entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "        plt.fill(np.array([high, 10000, 10000, high]), np.array([low, low, high, high]), entry_col, alpha=0.2)\n",
    "        counts_in_bins.append(np.sum(np.logical_and(\n",
    "            np.logical_and(ke_int <= high, ke_int > low),\n",
    "            ke_init > high)))\n",
    "    plt_conf.format_axis(xlabel=\"Initial energy\", ylabel=\"Interaction energy\")\n",
    "    print(f\"Used binning: {bin_edges}\")\n",
    "    print(f\"Found good bin occupancies: {counts_in_bins}\")\n",
    "    missed = ak.count(ke_init) - np.sum(counts_in_bins)\n",
    "    print(f\"{missed} missed events ({100*missed/(ak.count(ke_init)):.2f}%)\")\n",
    "    return plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning(np.array([3100, 2950, 2860, 2780, 2700, 2600, 2500, 2350, 2000]), ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_projections(coords):\n",
    "    # Weird norm means x axis is in understandable energy\n",
    "    return np.dot(coords, np.full(2, 1/2)), np.cross(coords, np.full(2, np.sqrt(0.5)))\n",
    "\n",
    "def plot_e_binning_projected(bin_edges, analysis_input, reco=True, plt_conf=None, plt_bins=60, lower=1800, upper=3500, dist=500):\n",
    "    ke_init = analysis_input.KE_init_reco if reco else analysis_input.KE_init_true\n",
    "    ke_int = analysis_input.KE_int_reco if reco else analysis_input.KE_int_true\n",
    "    if plt_conf is None:\n",
    "        plt_conf = Plots.PlotConfig()\n",
    "        plt_conf.SHOW_PLOT = True\n",
    "        plt_conf.SAVE_FOLDER = None\n",
    "    counts_in_bins = []\n",
    "    plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "    plt.hist2d(*gen_projections(np.array([ke_init, ke_int]).T),\n",
    "               bins=[np.linspace(lower, upper, plt_bins),\n",
    "                     np.linspace(0, dist*np.sqrt(2), plt_bins)],\n",
    "               norm=\"log\")\n",
    "    plt.colorbar()\n",
    "    grad1 = gen_projections(np.array([1, 0]))\n",
    "    grad1 = grad1[1]/grad1[0]\n",
    "    grad2 = gen_projections(np.array([0, 1]))\n",
    "    grad2 = grad2[1]/grad2[0]\n",
    "    for edge in bin_edges:\n",
    "        plt.axline((edge, 0), slope=grad1, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "        plt.axline((edge, 0), slope=grad2, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    for i, (high, low) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "        plt.fill(*gen_projections(np.array([[low, high, high, low],\n",
    "                                            [low, low, high, high]]).T),\n",
    "                 \"black\", alpha=0.3)\n",
    "        entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "        plt.fill(*gen_projections(np.array([[high, 10000, 10000, high],\n",
    "                                            [low, low, high, high]]).T),\n",
    "                 entry_col, alpha=0.2)\n",
    "        counts_in_bins.append(np.sum(np.logical_and(\n",
    "            np.logical_and(ke_int <= high, ke_int > low),\n",
    "            ke_init > high)))\n",
    "    plt_conf.format_axis(xlabel=\"Diagonal projection/Mev\", ylabel=\"Distance from diagonal\")\n",
    "    print(f\"Used binning: {bin_edges}\")\n",
    "    print(f\"Found good bin occupancies: {counts_in_bins}\")\n",
    "    missed = ak.count(ke_init) - np.sum(counts_in_bins)\n",
    "    print(f\"{missed} missed events ({100*missed/(ak.count(ke_init)):.2f}%)\")\n",
    "    return plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning_projected(np.array([3040, 2950, 2860, 2780, 2700, 2630, 2560, 2490, 2420, 2320, 1890]), ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_binning = np.array([2950, 2850, 2777, 2739, 2704, 2672, 2640, 2608, 2573, 2537, 2498, 2451, 2394, 2311, 0])\n",
    "plot_e_binning_projected(test_binning, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning_projected(opt_bins, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opt = opt_bins.copy()\n",
    "test_opt[0] += 10\n",
    "plot_e_binning_projected(test_opt, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_proj_width(upper_e, lower_e):\n",
    "    return lower_e, upper_e-lower_e\n",
    "    # coords = np.array([upper_e, lower_e]).T\n",
    "    # # Weird norm means x axis is in understandable energy\n",
    "    # return np.dot(coords, np.full(2, 1/2)), np.cross(coords, np.ones(2))\n",
    "\n",
    "def min_thresh_eval(in_bin, excluded):\n",
    "    min_count=3000\n",
    "    return np.where(in_bin > 3000, in_bin/(np.power(excluded,2)+1), 0)\n",
    "\n",
    "def includes_eval(in_bin, excluded):\n",
    "    return in_bin\n",
    "\n",
    "def missing_eval(in_bin, excluded):\n",
    "    return excluded\n",
    "\n",
    "def plot_e_binning_goodness(\n",
    "        analysis_input, eval_func, bin_edges=None, n_per_ax=100, e_view=True,\n",
    "        reco=True, plt_conf=None, lower=1800, upper=3500, count_thresh=None):\n",
    "    ke_init = analysis_input.KE_init_reco if reco else analysis_input.KE_init_true\n",
    "    ke_int = analysis_input.KE_int_reco if reco else analysis_input.KE_int_true\n",
    "    e_coords = np.array([ke_init, ke_int]).T\n",
    "\n",
    "    test_energies = np.linspace(lower, upper, n_per_ax, endpoint=False)\n",
    "    test_widths = upper - test_energies[::-1]\n",
    "    # Vectorised, but ~2x calculations needed\n",
    "    # (given we don't change results much between\n",
    "    # bin energies above the upper limit)\n",
    "    offset_es = e_coords[:, np.newaxis, :] - test_energies[:, np.newaxis]\n",
    "    int_e_diff = np.dot(offset_es, np.array([0, 1]))[:, :, np.newaxis]\n",
    "    init_e_diff = np.dot(offset_es, np.array([1, 0]))[:, :, np.newaxis]\n",
    "    in_bin = np.logical_and(int_e_diff > 0, int_e_diff <= test_widths)\n",
    "    missed = np.logical_and(in_bin, init_e_diff <= test_widths)\n",
    "    included = np.logical_and(in_bin, init_e_diff > test_widths)\n",
    "    loss = eval_func(np.sum(included, axis=0), np.sum(missed, axis=0))\n",
    "    if count_thresh is not None:\n",
    "        loss[included < count_thresh] = 0\n",
    "\n",
    "    lower_edges = np.repeat(test_energies[:, np.newaxis], n_per_ax, axis=1)\n",
    "    upper_edges = lower_edges + test_widths\n",
    "    if e_view:\n",
    "        form = lambda upp, loww : (upp, loww)\n",
    "    else:\n",
    "        form = lambda upp, loww : gen_proj_width(upp, loww)\n",
    "    if plt_conf is None:\n",
    "        plt_conf = Plots.PlotConfig()\n",
    "        plt_conf.SHOW_PLOT = True\n",
    "        plt_conf.SAVE_FOLDER = None\n",
    "    plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "    plt_binning = np.linspace(lower, upper, n_per_ax+1, endpoint=True)\n",
    "    if not e_view:\n",
    "        plt_binning = [plt_binning, upper-plt_binning[::-1]]\n",
    "    plt.hist2d(*form(upper_edges.flatten(), lower_edges.flatten()), weights=loss.flatten(),\n",
    "               bins=plt_binning, norm=\"log\")\n",
    "    plt.colorbar()\n",
    "    if bin_edges is not None:\n",
    "        plt.scatter(*form(bin_edges[:-1], bin_edges[1:]), color=\"red\", marker=\"x\", lw=2)\n",
    "        if e_view:\n",
    "            plt.step(*form(bin_edges[:-1], bin_edges[1:]), color=\"red\", ls=\":\", lw=1, where=\"post\")\n",
    "        else:\n",
    "            points = (bin_edges[:-1, np.newaxis]*np.array([1, 0])\n",
    "                      + bin_edges[1:, np.newaxis]*np.array([0, 1]))\n",
    "            widths = bin_edges[:-1, np.newaxis] - points\n",
    "            plt.plot(points.flatten(), widths.flatten(), color=\"red\", ls=\":\", lw=1)\n",
    "    # for edge in bin_edges:\n",
    "    #     plt.axline((edge, 0), slope=grad1, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    #     plt.axline((edge, 0), slope=grad2, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    # for i, (high, low) in enumerate(zip(bin_edges[:-1], bin_edges[1:])):\n",
    "    #     plt.fill(*form(np.array([low, high, high, low]),\n",
    "    #                    np.array([low, low, high, high])),\n",
    "    #             \"black\", alpha=0.3)\n",
    "    #     entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "    #     plt.fill(*form(np.array([high, 10000, 10000, high]),\n",
    "    #                    np.array([low, low, high, high])),\n",
    "    #             entry_col, alpha=0.2)\n",
    "    #     counts_in_bins.append(np.sum(np.logical_and(\n",
    "    #         np.logical_and(ke_int <= high, ke_int > low),\n",
    "    #         ke_init > high)))\n",
    "    if e_view:\n",
    "        plt_conf.format_axis(xlabel=\"Upper bin bound/Mev\", ylabel=\"Lower bin bound/MeV\")\n",
    "    else:\n",
    "        plt_conf.format_axis(xlabel=\"Low bin bound/Mev\", ylabel=\"Bin width/MeV\")\n",
    "    # print(f\"Used binning: {bin_edges}\")\n",
    "    # print(f\"Found good bin occupancies: {counts_in_bins}\")\n",
    "    # missed = ak.count(ke_init) - np.sum(counts_in_bins)\n",
    "    # print(f\"{missed} missed events ({100*missed/(ak.count(ke_init)):.2f}%)\")\n",
    "    return plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_coords = np.array([ai_template.KE_init_reco, ai_template.KE_int_reco]).T\n",
    "included, missing = gen_bin_width_info(2950, e_coords, 20, e_min=2750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(included > 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_optimiser(analysis_input, loss, min_occupancy_thresh, search_resolution=0.1, reco=True, e_max=None, e_min=None, verbose=True):\n",
    "    if reco:\n",
    "        e_init = analysis_input.KE_init_reco\n",
    "        e_int = analysis_input.KE_int_reco\n",
    "    else:\n",
    "        e_init = analysis_input.KE_init_true\n",
    "        e_int = analysis_input.KE_int_true\n",
    "    return bin_optimiser_es(\n",
    "        e_init, e_int, loss, min_occupancy_thresh,\n",
    "        search_resolution=search_resolution, e_max=e_max, e_min=e_min, verbose=verbose)\n",
    "\n",
    "def gen_bin_width_info(test_e, e_coords, resolution, e_bound=0, is_lower_bin=False):\n",
    "        test_widths = np.arange(0, np.abs(test_e-e_bound), resolution) + resolution\n",
    "        offset_e = e_coords - test_e\n",
    "        init_e_diff = offset_e[:, 0, np.newaxis]\n",
    "        int_e_diff = offset_e[:, 1, np.newaxis]\n",
    "        lower_bin_bound = 0 if is_lower_bin else -test_widths\n",
    "        upper_bin_bound = test_widths if is_lower_bin else 0\n",
    "        in_bin = np.logical_and(int_e_diff >= lower_bin_bound,\n",
    "                                int_e_diff < upper_bin_bound)\n",
    "        # We miss an event if both the interaction and initial energy\n",
    "        # are in the same bin. Note ke_init >= ke_int means condition\n",
    "        # init_e_diff >= -test_widths is inherent to in_bin\n",
    "        missed = np.logical_and(in_bin, init_e_diff < upper_bin_bound)\n",
    "        included = np.logical_and(in_bin, init_e_diff >= upper_bin_bound)\n",
    "        return included.sum(axis=0), np.sum(missed, axis=0)\n",
    "\n",
    "# def gen_bin_width_info(upper_e, e_coords, resolution, e_min=0):\n",
    "#         test_widths = np.arange(0, upper_e-e_min, resolution) + resolution\n",
    "#         offset_e = e_coords - upper_e\n",
    "#         init_e_diff = offset_e[:, 0, np.newaxis]\n",
    "#         int_e_diff = offset_e[:, 1, np.newaxis]\n",
    "#         in_bin = np.logical_and(int_e_diff >= -test_widths, int_e_diff < 0)\n",
    "#         # We miss an event if both the interaction and initial energy\n",
    "#         # are in the same bin. Note ke_init >= ke_int means condition\n",
    "#         # init_e_diff >= -test_widths is inherent to in_bin\n",
    "#         missed = np.logical_and(in_bin, init_e_diff <= 0)\n",
    "#         included = np.logical_and(in_bin, init_e_diff > 0)\n",
    "#         return included.sum(axis=0), np.sum(missed, axis=0)\n",
    "\n",
    "def bin_optimiser_es(ke_init, ke_int, loss_func, min_occupancy_thresh, search_resolution=0.1, e_max=None, e_min=None, verbose=True):\n",
    "    e_coords = np.array([ke_init, ke_int]).T\n",
    "    e_max = np.max(e_coords) if e_max is None else e_max+search_resolution\n",
    "    e_min = np.min(e_coords) if e_min is None else e_min+search_resolution\n",
    "    def _calc_next_bin(curr_edges, best_ind):\n",
    "        # best_ind + 1 from test_width[0] having a width of 1*search_resolution\n",
    "        return curr_edges[-1] - (best_ind+1)*search_resolution\n",
    "    bin_edges = []\n",
    "    upper_bin_low_edge = e_max\n",
    "    upper_found = False\n",
    "    # Uses a binomial-like (but base 10) search for best bins\n",
    "    resolution_order = np.floor(np.log10(search_resolution))\n",
    "    e_range_order = np.floor(np.log10(e_max - e_min)) - 1\n",
    "    if e_range_order > resolution_order:\n",
    "        scales = np.power(10, np.arange(0, 1+e_range_order-resolution_order)[::-1])\n",
    "    else:\n",
    "        scales = [1]\n",
    "    for scale in scales:\n",
    "        while not upper_found:\n",
    "            upper_bin_low_edge -= search_resolution*scale\n",
    "            if upper_bin_low_edge <= e_min:\n",
    "                raise Exception(\"No upper bin could be found\")\n",
    "            inc, miss = gen_bin_width_info(\n",
    "                upper_bin_low_edge, e_coords, search_resolution*scale,\n",
    "                e_bound=e_max, is_lower_bin=True)\n",
    "            good_bins = inc >= min_occupancy_thresh\n",
    "            if not np.any(good_bins):\n",
    "                continue\n",
    "            upper_found = True\n",
    "        # Rescan good bin with 10 times finer scale\n",
    "        upper_bin_low_edge += search_resolution*scale\n",
    "        upper_found=False\n",
    "    upper_bin_low_edge -= search_resolution # Remove after final search\n",
    "    # Calculate upper bin\n",
    "    good_indicies = np.arange(inc.size)[good_bins]\n",
    "    # Choose the smallest valid width minimising the missing events\n",
    "    # Don't need to consider events interaction above upper_e, since\n",
    "    # this is a constant offset, once an upper edge is chosen.\n",
    "    low_miss_mask = miss[good_indicies] <= np.min(miss[good_indicies])\n",
    "    best_selection = good_indicies[low_miss_mask][0]\n",
    "    up_bin_width = (best_selection+1) * search_resolution\n",
    "    bin_edges.append(upper_bin_low_edge + up_bin_width)\n",
    "    bin_edges.append(upper_bin_low_edge)\n",
    "    if verbose:\n",
    "        print(f\"Upper bin successfully set ({bin_edges[0]})\")\n",
    "    # Calculate remaining bins\n",
    "    inds = np.arange(np.ceil((bin_edges[-1]-e_min)/search_resolution), dtype=int)\n",
    "    while bin_edges[-1] > e_min:\n",
    "        if verbose:\n",
    "            print(f\"Next bin edge: {bin_edges[-1]}\")\n",
    "        inc, miss = gen_bin_width_info(\n",
    "            bin_edges[-1], e_coords, search_resolution, e_bound=e_min)\n",
    "        if not np.any(inc >= min_occupancy_thresh):\n",
    "            bin_edges.append(e_min)\n",
    "            if verbose:\n",
    "                print(f\"Insufficient occupancy, setting lower count to minimum energy: {e_min}\")\n",
    "            break\n",
    "        loss = loss_func(inc, miss)\n",
    "        best_loss_mask = loss <= np.min(loss)\n",
    "        best_selection = inds[best_loss_mask][0]\n",
    "        # Strips away the width of the selected bin from available inds\n",
    "        inds = inds[:-(best_selection+1)]\n",
    "        bin_edges.append(_calc_next_bin(bin_edges, best_selection))\n",
    "    print(f\"Optimisation complete, {len(bin_edges)-1} bins chosen.\")\n",
    "    return np.array(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_thresh_loss(in_bin, excluded):\n",
    "    min_count=3000\n",
    "    return np.where(in_bin > 3000, (np.power(excluded,2)+1)/in_bin, np.inf)\n",
    "opt_bins = bin_optimiser(ai_template, min_thresh_loss, 3000, search_resolution=0.1)\n",
    "print(opt_bins)\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, bin_edges=opt_bins, e_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_thresh_loss(in_bin, excluded):\n",
    "    min_count=3000\n",
    "    return np.where(in_bin > 3000, (np.power(excluded,2)+1)/in_bin, np.inf)\n",
    "opt_bins = bin_optimiser(ai_template, min_thresh_loss, 3000, search_resolution=0.1, e_max=2859.1)\n",
    "print(opt_bins)\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, bin_edges=opt_bins, e_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_count_loss(in_bin, excluded):\n",
    "    target_count=6000\n",
    "    min_count = 4000\n",
    "    missing_loss = np.power(excluded,1)#np.exp(excluded/100)#\n",
    "    target_count_loss = np.exp(6*np.abs(target_count-in_bin)/target_count)\n",
    "    return np.where(in_bin >= min_count, target_count_loss * missing_loss, np.inf)\n",
    "\n",
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "x = np.repeat(np.logspace(0, 4, 100)[:, np.newaxis], 100, axis=1)\n",
    "missing = np.repeat(np.logspace(0, 3, 100)[np.newaxis, :], 100, axis=0)\n",
    "plt.hist2d(\n",
    "    x.flatten(), missing.flatten(),\n",
    "    weights=target_count_loss(x.flatten(), missing.flatten()), norm=\"log\",\n",
    "    bins = [x[:, 0], missing[0, :]])\n",
    "plt.colorbar()\n",
    "plt_conf.format_axis(xlabel=\"Count in bin\", ylabel=\"Missing count\")#, xlog=True, ylog=True)\n",
    "plt_conf.end_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count_inv = lambda inc, exc: 1/target_count_loss(inc, exc)\n",
    "\n",
    "opt_bins = bin_optimiser(ai_template, target_count_loss, 4000, search_resolution=0.1)\n",
    "print(opt_bins)\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, target_count_inv, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning(opt_bins, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count_inv = lambda inc, exc: 1/target_count_loss(inc, exc)\n",
    "\n",
    "opt_bins = bin_optimiser(ai_template, target_count_loss, 4000, search_resolution=0.1)\n",
    "print(opt_bins)\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, target_count_inv, bin_edges=opt_bins, e_view=False)\n",
    "plot_e_binning(opt_bins, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning(opt_bins, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opt = opt_bins.copy()\n",
    "test_opt[0] -= 1\n",
    "plot_e_binning(test_opt, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning(opt_bins, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning_goodness(ai_template, includes_eval, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, e_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bins = np.array([3040, 2950, 2860, 2780, 2700, 2630, 2560, 2490, 2420, 2320, 1890])\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=test_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=test_bins, e_view=False)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, bin_edges=test_bins, e_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning_goodness(ai_template, includes_eval, e_view=True)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, e_view=True)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, e_view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bins = np.array([3040, 2950, 2860, 2780, 2700, 2630, 2560, 2490, 2420, 2320, 1890])\n",
    "plot_e_binning_goodness(ai_template, includes_eval, bin_edges=test_bins, e_view=True)\n",
    "plot_e_binning_goodness(ai_template, missing_eval, bin_edges=test_bins, e_view=True)\n",
    "plot_e_binning_goodness(ai_template, min_thresh_eval, bin_edges=test_bins, e_view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning_goodness(ai_template, min_thresh_eval, n_per_ax=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.array([ai_template.KE_init_reco, ai_template.KE_int_reco]).T\n",
    "pos_vec = np.array([1, 1])/np.sqrt(2)\n",
    "off_diag_size = np.cross(coords, pos_vec)\n",
    "diag_project = np.dot(coords, pos_vec)/np.sqrt(2)\n",
    "\n",
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(diag_project, off_diag_size,\n",
    "            bins=[np.linspace(1800, 3500, 60), np.linspace(0, 1000*np.sqrt(2), 60)], norm=\"log\")\n",
    "plt.colorbar()\n",
    "plt_conf.format_axis(xlabel=\"Diagonal projection/Mev\", ylabel=\"Distance from diagonal/MeV\")\n",
    "plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coords[0], pos_vec)\n",
    "np.cross(coords[0], pos_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_diag_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bin_pos=np.array([3300, 3300, 2950, 2860, 2780, 2700, 2600, 2500, 2000])\n",
    "counts_in_bins = []\n",
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_init_reco, ai_template.KE_int_reco, bins=np.linspace(1800, 3500, 60), norm=\"log\")\n",
    "plt.colorbar()\n",
    "for edge in test_bin_pos:\n",
    "    plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "for i, (high, low) in enumerate(zip(test_bin_pos[:-1], test_bin_pos[1:])):\n",
    "    plt.fill(np.array([low, high, high, low]), np.array([low, low, high, high]), \"black\", alpha=0.3)\n",
    "    entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "    plt.fill(np.array([high, 10000, 10000, high]), np.array([low, low, high, high]), entry_col, alpha=0.2)\n",
    "    counts_in_bins.append(np.sum(np.logical_and(\n",
    "        np.logical_and(\n",
    "            ai_template.KE_int_reco <= high,\n",
    "            ai_template.KE_int_reco > low),\n",
    "        ai_template.KE_init_reco > high)))\n",
    "plt_conf.format_axis(xlabel=\"Initial energy\", ylabel=\"Interaction energy\")\n",
    "plt_conf.end_plot()\n",
    "print(test_bin_pos)\n",
    "print(counts_in_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bin_pos=args.energy_slices.pos\n",
    "counts_in_bins = []\n",
    "plt_conf.setup_figure(figsize=(8.5, 6))\n",
    "plt.hist2d(ai_template.KE_init_reco, ai_template.KE_int_reco, bins=np.linspace(1800, 3500, 60), norm=\"log\")\n",
    "plt.colorbar()\n",
    "for edge in test_bin_pos:\n",
    "    plt.axvline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "    plt.axhline(edge, color=\"red\", linestyle=\"dotted\", linewidth=2)\n",
    "for i, (high, low) in enumerate(zip(test_bin_pos[:-1], test_bin_pos[1:])):\n",
    "    plt.fill(np.array([low, high, high, low]), np.array([low, low, high, high]), \"black\", alpha=0.3)\n",
    "    entry_col = \"yellow\" if i%2 == 0 else \"orange\"\n",
    "    plt.fill(np.array([high, 10000, 10000, high]), np.array([low, low, high, high]), entry_col, alpha=0.2)\n",
    "    counts_in_bins.append(np.sum(np.logical_and(\n",
    "        np.logical_and(\n",
    "            ai_template.KE_int_reco <= high,\n",
    "            ai_template.KE_int_reco > low),\n",
    "        ai_template.KE_init_reco > high)))\n",
    "plt_conf.format_axis(xlabel=\"Initial energy\", ylabel=\"Interaction energy\")\n",
    "plt_conf.end_plot()\n",
    "print(test_bin_pos)\n",
    "print(counts_in_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges_loss(opt_out.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges_loss(np.array([3300, 2950, 2860, 2780, 2700, 2600, 2500, 2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 6\n",
    "upper_bound = 3500\n",
    "lower_bound = 1800\n",
    "\n",
    "def bin_edges_loss(edges):\n",
    "    target_min_occupancy = 3000\n",
    "    missing = []\n",
    "    included = []\n",
    "    tot_evts = ak.count(ai_template.KE_int_reco)\n",
    "    for low, high in zip(edges[1:], edges[:-1]):\n",
    "        int_mask = np.logical_and(\n",
    "            ai_template.KE_int_reco <= high,\n",
    "            ai_template.KE_int_reco > low)\n",
    "        missing.append(np.sum(np.logical_and(\n",
    "            int_mask, ai_template.KE_init_reco <= high)))\n",
    "        included.append(np.sum(np.logical_and(\n",
    "            int_mask, ai_template.KE_init_reco > high)))\n",
    "    # min_occupancy_penalty = np.sum([np.exp((3000-i)*(1/1000)) for i in included])\n",
    "    min_occupancy_penalty = np.sum([np.log((tot_evts+target_min_occupancy-i)*(1/tot_evts)) for i in included])\n",
    "    smoothing_penalty = np.var(included)\n",
    "    # total_miss_penalty = sum([(m**2)/i for i, m in zip(included, missing)])\n",
    "    miss_pen_mat = np.eye(edges.size-1) - 0.5*(np.eye(edges.size-1, k=1) + np.eye(edges.size-1, k=-1))\n",
    "    total_miss_penalty = np.sum((miss_pen_mat@np.array(missing))/np.array(included))\n",
    "    return 5*total_miss_penalty + min_occupancy_penalty\n",
    "    return 10*total_miss_penalty + smoothing_penalty*(1/5000) + min_occupancy_penalty*(2/1)\n",
    "\n",
    "constraint_mat = np.eye(n_bins+3, n_bins+1, k=0) - np.eye(n_bins+3, n_bins+1, k=-1)\n",
    "constraint_mat[0,0] = 1\n",
    "constraint_mat[-1,-1] = 1\n",
    "constraint_upper = np.concatenate([np.array([upper_bound]), np.zeros(n_bins+1), np.array([upper_bound])])\n",
    "constraint_lower = np.concatenate([np.array([lower_bound]), np.full(n_bins+1, -np.inf), np.array([lower_bound])])\n",
    "print(constraint_mat)\n",
    "print(constraint_upper)\n",
    "print(constraint_lower)\n",
    "lin_constraint = opt.LinearConstraint(constraint_mat, lb=constraint_lower, ub=constraint_upper)\n",
    "\n",
    "init_pred = np.concatenate([np.array([lower_bound]),\n",
    "                            np.linspace(lower_bound+300, upper_bound-300, n_bins-1),\n",
    "                            np.array([upper_bound])])[::-1]\n",
    "# init_pred = np.array([3300, 2950, 2780, 2700, 2600, 2500, 2000])\n",
    "print(init_pred)\n",
    "\n",
    "opt_out = opt.minimize(bin_edges_loss, init_pred, constraints=lin_constraint, method=\"COBYLA\", options={\"maxiter\":10000})\n",
    "print(opt_out)\n",
    "print(opt_out.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_e_binning(opt_out.x, ai_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slices = copy.copy(args.energy_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ s for s in dir(test_slices) if s[:2] != \"__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.arange(10)\n",
    "poss = np.array([3100, 2900, 2800, 2750, 2700, 2650, 2600, 2500, 2300, 2100])\n",
    "new_slice = test_slices.Slice(nums, poss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_slice.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices(1900).num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(args.energy_slices))\n",
    "print(type(new_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.min_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ai_data.outside_tpc_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices(3000).num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices(1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices(ai_template.KE_int_reco).num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_slices, int_slices = Slicing.EnergySlice.SliceNumbers(\n",
    "            ai_data.KE_int_reco, ai_data.KE_init_reco, ai_data.outside_tpc_reco, args.energy_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_data.KE_int_reco[:10])\n",
    "print(int_slices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(init_slices, return_counts=True))\n",
    "print(np.unique(int_slices, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(AnalysisInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_temp_unweighted = copy.deepcopy(ai_template)\n",
    "ai_temp_unweighted.weights = None\n",
    "ai_temp_unweighted.outside_tpc_true = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_template = AnalysisInputs.AnalysisInputGNN(**vars(ai_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hists_data = ai_data.CreateHistograms(args.energy_slices, True)\n",
    "out_hists_template = ai_template.CreateHistograms(args.energy_slices, False)\n",
    "out_hists_template_reco = ai_template.CreateHistograms(args.energy_slices, True)\n",
    "out_hists_template_unw = ai_temp_unweighted.CreateHistograms(args.energy_slices, False)\n",
    "out_hists_template_reco_unw = ai_temp_unweighted.CreateHistograms(args.energy_slices, True)\n",
    "# out_hists_data = ai_data.CreateHistograms(new_slice, True)\n",
    "# out_hists_template = ai_template.CreateHistograms(new_slice, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tai = ai_temp_unweighted\n",
    "print([np.all(a == b) for a, b in zip(\n",
    "    Slicing.EnergySlice.CountingExperimentUnclassified(\n",
    "        ai_data.KE_int_reco, ai_data.KE_init_reco, ai_data.outside_tpc_reco,\n",
    "        args.energy_slices, weights = None),\n",
    "    Slicing.EnergySlice.CountingExperimentUnclassified(\n",
    "        tai.KE_int_reco, tai.KE_init_reco, tai.outside_tpc_reco,\n",
    "        args.energy_slices, weights = tai.weights))])\n",
    "print([np.all(a == b) for a, b in zip(\n",
    "    list(tai.CreateHistograms(args.energy_slices, True).values()),\n",
    "    Slicing.EnergySlice.CountingExperimentUnclassified(\n",
    "        tai.KE_int_reco, tai.KE_init_reco, tai.outside_tpc_reco,\n",
    "        args.energy_slices, weights = tai.weights))])\n",
    "print([np.all(a == b) for a, b in zip(\n",
    "    list(ai_temp_unweighted.CreateHistograms(args.energy_slices, True).values()),\n",
    "    list(ai_template.CreateHistograms(args.energy_slices, True).values()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_template.exclusive_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hists_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_hists_data[\"int\"])\n",
    "print(np.unique(out_hists_data[\"int_evt_indicies\"], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(out_hists_template[\"int_evt_indicies\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key: np.all(ai_template.classification_info[key] == ai_data.classification_info[key]) for key in ai_template.classification_info.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ai_template.gnn_scores == ai_data.gnn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.all(a == b) for a, b in zip(\n",
    "    Slicing.EnergySlice.CountingExperimentUnclassified(\n",
    "        ai_data.KE_int_reco, ai_data.KE_init_reco, ai_data.outside_tpc_reco,\n",
    "        args.energy_slices, weights = None),\n",
    "    Slicing.EnergySlice.CountingExperimentUnclassified(\n",
    "        ai_template.KE_int_reco, ai_template.KE_init_reco, ai_template.outside_tpc_reco,\n",
    "        args.energy_slices, weights = None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper Asimov version\n",
    "gens_true = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "temp_hists_dict = out_hists_template\n",
    "temp_ai = ai_template\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # # All templates\n",
    "    # temp_mask = np.full_like(ai_template.KE_int_reco, True, dtype=bool)\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # With bad energy slices\n",
    "    temp_mask = temp_hists_dict[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens_true.append(Fitter.DistGenCorr(\n",
    "        temp_ai.gnn_scores[temp_mask],\n",
    "        temp_ai.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        temp_ai.exclusive_process[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        template_weights = temp_ai.weights,\n",
    "        labels=list(temp_ai.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, unweighted template\n",
    "gens_true = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "temp_hists_dict = out_hists_template_unw\n",
    "temp_ai = ai_temp_unweighted\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # # All templates\n",
    "    # temp_mask = np.full_like(ai_template.KE_int_reco, True, dtype=bool)\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # With bad energy slices\n",
    "    temp_mask = temp_hists_dict[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens_true.append(Fitter.DistGenCorr(\n",
    "        temp_ai.gnn_scores[temp_mask],\n",
    "        temp_ai.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        temp_ai.exclusive_process[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        template_weights = temp_ai.weights,\n",
    "        labels=list(temp_ai.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, unweighted template, reco slicing\n",
    "gens_true = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "temp_hists_dict = out_hists_template_reco_unw\n",
    "temp_ai = ai_temp_unweighted\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # # All templates\n",
    "    # temp_mask = np.full_like(ai_template.KE_int_reco, True, dtype=bool)\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # With bad energy slices\n",
    "    temp_mask = temp_hists_dict[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens_true.append(Fitter.DistGenCorr(\n",
    "        temp_ai.gnn_scores[temp_mask],\n",
    "        temp_ai.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        temp_ai.exclusive_process[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        template_weights = temp_ai.weights,\n",
    "        labels=list(temp_ai.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, reco slicing, weighted template\n",
    "gens_true = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "temp_hists_dict = out_hists_template_reco\n",
    "temp_ai = ai_template\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # # All templates\n",
    "    # temp_mask = np.full_like(ai_template.KE_int_reco, True, dtype=bool)\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # With bad energy slices\n",
    "    temp_mask = temp_hists_dict[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens_true.append(Fitter.DistGenCorr(\n",
    "        temp_ai.gnn_scores[temp_mask],\n",
    "        temp_ai.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        temp_ai.exclusive_process[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        template_weights = temp_ai.weights,\n",
    "        labels=list(temp_ai.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No truth version\n",
    "gens = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # With bad energy slices\n",
    "    temp_mask = out_hists_template[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens.append(Fitter.DistGenCorr(\n",
    "        ai_template.gnn_scores[temp_mask],\n",
    "        ai_template.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        labels=list(ai_template.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With truth version\n",
    "args_c = Utils.args_to_dict(args)\n",
    "graph_path_params, norm_path = cgp._get_graph_info(evts_mc_2, args_c, \"mc\")\n",
    "gnn_model = Models.load_model_from_file(\n",
    "    args_c[\"gnn_model_path\"],\n",
    "    new_data_folder=graph_path_params[\"folder_path\"],\n",
    "    new_norm=norm_path)\n",
    "_, truth_regions = Models.get_predictions(\n",
    "    gnn_model,\n",
    "    graph_path_params[\"schema_path\"],\n",
    "    graph_path_params[\"test_path\"])\n",
    "\n",
    "gens_true = []\n",
    "init_preds = []\n",
    "n_data = []\n",
    "n_temps = []\n",
    "for i in range(args.energy_slices.max_num):\n",
    "    # All templates\n",
    "    temp_mask = np.full_like(ai_template.KE_int_reco, True, dtype=bool)\n",
    "    # # No bad templates\n",
    "    # temp_mask = args.energy_slices(ai_template.KE_int_reco).num == i\n",
    "    # # With bad energy slices\n",
    "    # temp_mask = out_hists_template[\"int_evt_indicies\"] == i\n",
    "    n_temps.append(np.sum(temp_mask))\n",
    "    data_mask = out_hists_data[\"int_evt_indicies\"] == i\n",
    "    n_data.append(np.sum(data_mask))\n",
    "    gens_true.append(Fitter.DistGenCorr(\n",
    "        ai_template.gnn_scores[temp_mask],\n",
    "        ai_template.exclusive_process[temp_mask],\n",
    "        ai_data.gnn_scores[data_mask],\n",
    "        truth_regions[data_mask],\n",
    "        bins=12, fix_bin_range=(0,1),\n",
    "        labels=list(ai_template.classification_info.keys())))\n",
    "    init_preds.append(np.histogram(ai_data.gnn_preds[data_mask], bins=np.arange(ai_data.gnn_scores.shape[1] + 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data slice occupancies, first bin is bad events:\")\n",
    "print(out_hists_data[\"int\"])\n",
    "print(\"True template slice occupancies, first bin is bad events:\")\n",
    "print(out_hists_template[\"int\"])\n",
    "print(\"Reco template slice occupancies, first bin is bad events:\")\n",
    "print(out_hists_template_reco[\"int\"])\n",
    "print(\"(data, template) slice occupancies (no bad events bin):\")\n",
    "print(list(zip(n_data, n_temps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_outs = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, unweighted template\n",
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, weighted template, reco_slicing\n",
    "print([np.all(g.sample_template_like_data() == g.sample_data()) for g in gens_true])\n",
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, unweighted template\n",
    "print([np.all(g.sample_template_like_data() == g.sample_data()) for g in gens_true])\n",
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asimov version, unweighted template, reco slicing\n",
    "print([np.all(g.sample_template_like_data() == g.sample_data()) for g in gens_true])\n",
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper Asimov version\n",
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_outs_w_true = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_outs_all_temp = [Fitter.generator_fit(g, init_preds=p) for g, p in zip(gens_true, init_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_templates(templates, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure(2, 2, figsize=(20, 12), title=\"Templates\")\n",
    "    for i, temp in enumerate(labels):\n",
    "        ax = axes[1-(i//2), i%2]\n",
    "        ax.set_title(f\"{temp} template\")\n",
    "        for j, lab in enumerate(labels):\n",
    "            lw = 3 + 2*(temp == lab)\n",
    "            sum_axes = tuple(k for k in range(len(labels)) if k != j)\n",
    "            ax.hist(\n",
    "                bins[j][:-1],\n",
    "                **plt_cfg.gen_kwargs(\n",
    "                    type=\"hist\", index=j, bins=bins[j],\n",
    "                    weights=templates[i].sum(axis=sum_axes), label=lab, lw=lw))\n",
    "        plt_cfg.format_axis(ax, xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()\n",
    "\n",
    "def plot_corr_dist(info, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure()\n",
    "    for j, lab in enumerate(labels):\n",
    "        sum_axes = tuple(k for k in range(len(labels)) if k != j)\n",
    "        plt.hist(\n",
    "            bins[j][:-1],\n",
    "            **plt_cfg.gen_kwargs(\n",
    "                type=\"hist\", index=j, bins=bins[j],\n",
    "                weights=info.sum(axis=sum_axes), label=lab))\n",
    "    plt_cfg.format_axis(xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, g in enumerate(gens_true):\n",
    "    print(f\"Slice index {s}\")\n",
    "    plot_corr_templates(g.sample_template(), g.bin_edges, plt_conf, labels=list(ai_template.classification_info.keys()))\n",
    "    plot_corr_dist(g.sample_template_like_data(), g.bin_edges, plt_conf, labels=list(ai_template.classification_info.keys()))\n",
    "    plot_corr_dist(g.sample_data(), g.bin_edges, plt_conf, labels=list(ai_template.classification_info.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = np.array([list(f.values) for f in fit_outs])\n",
    "uncs = np.array([list(f.errors) for f in fit_outs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = np.array([list(f.values) for f in fit_outs_w_true])\n",
    "uncs = np.array([list(f.errors) for f in fit_outs_w_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fit_outs_w_true:\n",
    "    print(f)\n",
    "    f.visualize()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(ai_template.classification_info.keys())\n",
    "fitted_hists_data = out_hists_data.copy()\n",
    "for i, lab in enumerate(labels):\n",
    "    fitted_hists_data[\"int_\"+lab] = yields[:, i]\n",
    "    fitted_hists_data[\"unc_int_\"+lab] = uncs[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NewCrossSection(\n",
    "#         n_int_ex : np.ndarray,\n",
    "#         # n_int : np.ndarray,\n",
    "#         n_inc : np.ndarray,\n",
    "#         dEdX : np.ndarray,\n",
    "#         dE : float,\n",
    "#         n_int_ex_err : np.ndarray = None,\n",
    "#         # n_int_err : np.ndarray = None,\n",
    "#         n_inc_err : np.ndarray = None) -> tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\" Compute exclusive cross sections. If interactions errors are not provided, staticial uncertainties are used (poisson for incident, binomial for interactions).\n",
    "\n",
    "#     Args:\n",
    "#         n_int_ex (np.ndarray): exclusive interactions\n",
    "#         n_int (np.ndarray): interactions\n",
    "#         n_inc (np.ndarray): incident counts\n",
    "#         dEdX (np.ndarray): slice dEdX\n",
    "#         dE (float): energy slice width\n",
    "#         n_int_ex_err (np.ndarray, optional): exclusive interaction errors. Defaults to None.\n",
    "#         n_int_err (np.ndarray, optional): interaction errors. Defaults to None.\n",
    "#         n_inc_err (np.ndarray, optional): incident count errors. Defaults to None.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple[np.ndarray, np.ndarray]: _description_\n",
    "#     \"\"\"\n",
    "#     NA = 6.02214076e23\n",
    "#     factor = (np.array(dEdX) * 10**27 * etools.BetheBloch.A\n",
    "#                 / (etools.BetheBloch.rho * NA * dE))\n",
    "\n",
    "#     # n_interact_ratio = nandiv(n_int_ex, n_int)\n",
    "#     n_survived = n_inc - n_int\n",
    "\n",
    "#     if n_inc_err is not None:\n",
    "#         var_inc_inclusive = n_inc_err**2\n",
    "#     else:\n",
    "#         var_inc_inclusive = n_inc # poisson variance\n",
    "\n",
    "#     if n_int_err is not None:\n",
    "#         var_int = n_int_err**2\n",
    "#     else:\n",
    "#         var_int = n_int * (1 - nandiv(n_int, n_inc)) # binomial uncertainty\n",
    "\n",
    "#     if n_int_ex_err is not None:\n",
    "#         var_int_ex = n_int_ex_err**2\n",
    "#     else:\n",
    "#         var_int_ex = n_int_ex * (1 - nandiv(n_int_ex, n_inc)) # binomial uncertainty\n",
    "\n",
    "\n",
    "#     xs = factor * n_interact_ratio * nanlog(nandiv(n_inc, n_inc - n_int_ex))\n",
    "\n",
    "#     diff_n_int_ex = nandiv(xs, n_int_ex)\n",
    "#     diff_n_inc = factor * n_interact_ratio * (nandiv(1, n_inc) - nandiv(1, n_survived))\n",
    "#     diff_n_int = factor * n_interact_ratio * nandiv(1, n_survived) - nandiv(xs, n_int)\n",
    "\n",
    "#     xs_err = ((diff_n_int_ex**2 * var_int_ex)\n",
    "#                 + (diff_n_inc**2 * var_inc_inclusive)\n",
    "#                 + (diff_n_int**2 * var_int))**0.5\n",
    "#     return np.array(xs, dtype = float), np.array(xs_err, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.energy_slices.pos_bins)\n",
    "print(args.energy_slices.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_hists_data[\"int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_hists_data[\"inc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_hists_data[\"int\"][1:-1])\n",
    "print(fitted_hists_data[\"inc\"][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_hists_data[\"int\"][1:-1] * (1 - Utils.nandiv(fitted_hists_data[\"int\"][1:-1], fitted_hists_data[\"inc\"][1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos_bins[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos_bins[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_hists_data[\"int_\"+lab].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_bin_energies = 0.5*(args.energy_slices.pos[1:] + args.energy_slices.pos[:-1])\n",
    "xsecs = {\"bin_centre_e\": centre_bin_energies}\n",
    "for lab in labels:\n",
    "    xsec, unc = Slicing.EnergySlice.CrossSection(\n",
    "        fitted_hists_data[\"int_\"+lab],\n",
    "        fitted_hists_data[\"int\"][1:args.energy_slices.max_num+1],\n",
    "        fitted_hists_data[\"inc\"][1:args.energy_slices.max_num+1],\n",
    "        EnergyTools.BetheBloch.meandEdX(\n",
    "            centre_bin_energies,\n",
    "            Particle.from_pdgid(211)),\n",
    "        args.energy_slices.width,\n",
    "        n_int_ex_err = fitted_hists_data[\"unc_int_\"+lab])\n",
    "    xsecs.update({\"xsec_\"+lab: xsec, \"unc_\"+lab:unc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.energy_slices.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g44xsec = cross_section.GeantCrossSections(file=\"/users/wx21978/projects/pion-phys/pi0-analysis/analysis/data/g4_xs.root\", energy_range=[2000, 3100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g44xsec.Plot(\"all\")\n",
    "plt.show()\n",
    "g44xsec.Plot(\"absorption\")\n",
    "plt.show()\n",
    "g44xsec.Plot(\"charge_exchange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_c = Utils.args_to_dict(args)\n",
    "graph_path_params, norm_path = cgp._get_graph_info(evts_mc_2, args_c, \"mc\")\n",
    "gnn_model = Models.load_model_from_file(\n",
    "    args_c[\"gnn_model_path\"],\n",
    "    new_data_folder=graph_path_params[\"folder_path\"],\n",
    "    new_norm=norm_path)\n",
    "_, truth_regions = Models.get_predictions(\n",
    "    gnn_model,\n",
    "    graph_path_params[\"schema_path\"],\n",
    "    graph_path_params[\"test_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lab in enumerate([\"Abs.\", \"CEx.\", \"Pion\"]):\n",
    "    fitted_hists_data[\"true_\"+lab] = np.array([np.sum(truth_regions[fitted_hists_data[\"int_evt_indicies\"]==j] == i) for j in range(args.energy_slices.max_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_hists_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Fitter.DistGenCorr(\n",
    "    all_pred, all_truth,\n",
    "    all_pred, all_truth,\n",
    "    data_weights=evt_weights.to_numpy(),\n",
    "    template_extra=all_n_pfos, data_extra=all_n_pfos,\n",
    "    bins=12, fix_bin_range=(0,1), labels=[\"Abs.\", \"CEx.\", \"Pion\"],\n",
    "    extra_bins = test_extra_bins_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_end = \"data_models/Model_data_112_PNA\"\n",
    "# model_path = \"/users/wx21978/projects/pion-phys/pi0-analysis/analysis/gnn-data/\" + path_end\n",
    "# model_path = \"/users/wx21978/projects/pion-phys/analyses/3GeV_MC_only/gnn_data/models/Model_data_PNA_0\"\n",
    "model_path = \"/users/wx21978/projects/pion-phys/analyses/3GeV_hm01/gnn_data/models/Model_data_PNA_3_out\"\n",
    "# model_path = \"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/models/Model_data_PNA_logits_erf\"\n",
    "\n",
    "# which_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/pi0-analysis/analysis/gnn-data/3GeVMC00_data_no_mom_bdt_scores_norms/\")\n",
    "# which_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_MC_only/gnn_data/3GeVMC_Set01_final_02-08-24/\")\n",
    "# which_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set03_final_06-08-24/\")\n",
    "which_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set03_final_07-08-24/\")\n",
    "\n",
    "# data_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_MC_Set02_final_07-08-24\")\n",
    "# template_path_params = DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_MC_Set01_final_07-08-24\")\n",
    "\n",
    "data_path_params = [\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set00_final_07-08-24/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set01_final_07-08-24/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set02_final_07-08-24/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set03_final_07-08-24/\")]\n",
    "\n",
    "template_path_params = [\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_MC_Set01_final_07-08-24\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_MC_Set02_final_07-08-24\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/models/Model_data_PNA_3_out\"\n",
    "\n",
    "data_path_params = [\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set00_comb_pi_24-10-21/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set01_comb_pi_24-10-21/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set02_comb_pi_24-10-21/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeV_data_Set03_comb_pi_24-10-21/\")]\n",
    "\n",
    "template_path_params = [\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeVMC_Set01_comb_pi_24-10-18/\"),\n",
    "    DataPreparation.create_filepath_dictionary(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/3GeVMC_Set02_comb_pi_24-10-18/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_data_simple = Models.load_model_from_file(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/models/Model_data_PNA_erf\", new_data_folder=data_path_params[0][\"folder_path\"])\n",
    "loaded_model_data_simple_new_norm = Models.load_model_from_file(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/models/Model_data_PNA_erf\", new_data_folder=data_path_params[0][\"folder_path\"], new_norm=data_path_params[0][\"norm_path\"])\n",
    "loaded_model_mc_simple = Models.load_model_from_file(\"/users/wx21978/projects/pion-phys/analyses/3GeV_both/gnn_data/models/Model_data_PNA_erf\", new_data_folder=template_path_params[0][\"folder_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_pred_simple_new_norm = []\n",
    "all_data_pred_simple = []\n",
    "for i in range(len(data_path_params)):\n",
    "    all_data_pred_simple.append(Models.get_data_predictions(\n",
    "        loaded_model_data_simple, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"])[0])\n",
    "    all_data_pred_simple_new_norm.append(Models.get_data_predictions(\n",
    "        loaded_model_data_simple_new_norm, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"])[0])\n",
    "\n",
    "all_mc_pred_simple = []\n",
    "all_mc_truth_simple = []\n",
    "for i in range(len(template_path_params)):\n",
    "    this_pred, this_truth = Models.get_predictions(\n",
    "        loaded_model_mc_simple, template_path_params[i][\"schema_path\"], template_path_params[i][\"test_path\"])\n",
    "    all_mc_pred_simple.append(this_pred)\n",
    "    all_mc_truth_simple.append(this_truth)\n",
    "\n",
    "all_data_pred_simple = np.concatenate(all_data_pred_simple, axis=0)\n",
    "all_data_pred_simple_new_norm = np.concatenate(all_data_pred_simple_new_norm, axis=0)\n",
    "all_mc_pred_simple = np.concatenate(all_mc_pred_simple, axis=0)\n",
    "all_mc_truth_simple = np.concatenate(all_mc_truth_simple, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_data_new_norm = Models.load_model_from_file(model_path, new_data_folder=data_path_params[0][\"folder_path\"], new_norm=data_path_params[0][\"norm_path\"])\n",
    "loaded_model_mc = Models.load_model_from_file(model_path, new_data_folder=template_path_params[0][\"folder_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_data = Models.load_model_from_file(model_path, new_data_folder=data_path_params[0][\"folder_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred, temp_truth = Models.get_predictions(\n",
    "    loaded_model_mc, template_path_params[0][\"schema_path\"], template_path_params[0][\"test_path\"])\n",
    "mc_data_pred, mc_data_truth = Models.get_predictions(\n",
    "    loaded_model_mc, template_path_params[1][\"schema_path\"], template_path_params[1][\"test_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note \"pion\" refers to the pion classification score, this there is a prediction for each shape, which may be used to count PFOs\n",
    "_, temp_pions = Models.get_predictions(\n",
    "    loaded_model_mc, template_path_params[0][\"schema_path\"], template_path_params[0][\"test_path\"], other_truth=\"pion\")\n",
    "temp_n_pfos = ak.num(temp_pions, axis=1).to_numpy()\n",
    "del temp_pions\n",
    "_, mc_data_pions = Models.get_predictions(\n",
    "    loaded_model_mc, template_path_params[1][\"schema_path\"], template_path_params[1][\"test_path\"], other_truth=\"pion\")\n",
    "mc_data_n_pfos = ak.num(mc_data_pions, axis=1).to_numpy()\n",
    "del mc_data_pions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_evts = DataPreparation.load_param_events(template_path_params[0], new_ntuples_folder=\"/storage/0\", depth=2)\n",
    "_, temp_ids = Models.get_data_predictions(\n",
    "    loaded_model_mc, template_path_params[0][\"schema_path\"], template_path_params[0][\"test_path\"])\n",
    "if np.all(DataPreparation.make_evt_ids(temp_evts) == temp_ids):\n",
    "    temp_true_energies = temp_evts.trueParticles.beam_KE_front_face\n",
    "    temp_energies = temp_evts.recoParticles.beam_inst_P\n",
    "else:\n",
    "    raise ValueError(\"Template ids not matching\")\n",
    "del temp_evts\n",
    "mc_data_evts = DataPreparation.load_param_events(template_path_params[1], new_ntuples_folder=\"/storage/0/\", depth=2)\n",
    "_, mc_data_ids = Models.get_data_predictions(\n",
    "    loaded_model_mc, template_path_params[1][\"schema_path\"], template_path_params[1][\"test_path\"])\n",
    "if np.all(DataPreparation.make_evt_ids(mc_data_evts) == mc_data_ids):\n",
    "    mc_data_true_energies = mc_data_evts.trueParticles.beam_KE_front_face\n",
    "    mc_data_energies = mc_data_evts.recoParticles.beam_inst_P\n",
    "else:\n",
    "    raise ValueError(\"MC data ids not matching\")\n",
    "del mc_data_evts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_pred_new_norm = []\n",
    "all_data_n_pfos_new_norm = []\n",
    "for i in range(len(data_path_params)):\n",
    "    all_data_pred_new_norm.append(Models.get_data_predictions(\n",
    "        loaded_model_data_new_norm, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"])[0])\n",
    "    all_data_n_pfos_new_norm.append(Models.get_data_predictions(\n",
    "        loaded_model_data_new_norm, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"], which_pred=3)[0].row_lengths().numpy()) # pion predictions\n",
    "\n",
    "all_data_pred_new_norm = np.concatenate(all_data_pred_new_norm, axis=0)\n",
    "all_data_n_pfos_new_norm = np.concatenate(all_data_n_pfos_new_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred, _ = Models.get_data_predictions(\n",
    "    loaded_model_data, data_path_params[0][\"schema_path\"], data_path_params[0][\"test_path\"])\n",
    "\n",
    "# data_pion_preds, _ = Models.get_data_predictions(\n",
    "#     loaded_model_data, data_path_params[0][\"schema_path\"], data_path_params[0][\"test_path\"], which_pred=3) # pion predictions\n",
    "# data_n_pfos = data_pion_preds.row_lengths().numpy()\n",
    "# del data_pion_preds\n",
    "\n",
    "all_data_pred = []\n",
    "all_data_n_pfos = []\n",
    "all_data_energies = []\n",
    "for i in range(len(data_path_params)):\n",
    "    preds, ids = Models.get_data_predictions(\n",
    "        loaded_model_data, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"])\n",
    "    all_data_pred.append(preds)\n",
    "    all_data_n_pfos.append(Models.get_data_predictions(\n",
    "        loaded_model_data, data_path_params[i][\"schema_path\"], data_path_params[i][\"test_path\"], which_pred=3)[0].row_lengths().numpy()) # pion predictions\n",
    "    these_evts = DataPreparation.load_param_events(data_path_params[i], new_ntuples_folder=\"/storage/0/\", depth=2)\n",
    "    if np.all(DataPreparation.make_evt_ids(these_evts) == ids):\n",
    "        all_data_energies.append(these_evts.recoParticles.beam_inst_P)\n",
    "    else:\n",
    "        raise ValueError(f\"Data {i} ids not matching\")\n",
    "del these_evts\n",
    "\n",
    "# print([d.shape for d in all_data_pred])\n",
    "# print([d.shape for d in all_data_n_pfos])\n",
    "all_data_pred = np.concatenate(all_data_pred, axis=0)\n",
    "all_data_n_pfos = np.concatenate(all_data_n_pfos, axis=0)\n",
    "all_data_energies = np.concatenate(all_data_energies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_over_events(func, events):\n",
    "    return ak.concatenate([func(e) for e in events], axis=0)\n",
    "\n",
    "temp_evts = [DataPreparation.load_param_events(pp, new_ntuples_folder=\"/storage/0/\", depth=2) for pp in template_path_params]\n",
    "data_evts = [DataPreparation.load_param_events(pp, new_ntuples_folder=\"/storage/0/\", depth=2) for pp in data_path_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_templates(templates, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure(2, 2, figsize=(20, 12), title=\"Templates\")\n",
    "    for i, temp in enumerate(labels):\n",
    "        ax = axes[1-(i//2), i%2]\n",
    "        ax.set_title(f\"{temp} template\")\n",
    "        for j, lab in enumerate(labels):\n",
    "            lw = 3 + 2*(temp == lab)\n",
    "            sum_axes = tuple(k for k in range(len(labels)) if k != j)\n",
    "            ax.hist(\n",
    "                bins[j][:-1],\n",
    "                **plt_cfg.gen_kwargs(\n",
    "                    type=\"hist\", index=j, bins=bins[j],\n",
    "                    weights=templates[i].sum(axis=sum_axes), label=lab, lw=lw))\n",
    "        plt_cfg.format_axis(ax, xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()\n",
    "\n",
    "def plot_corr_dist(info, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure()\n",
    "    for j, lab in enumerate(labels):\n",
    "        sum_axes = tuple(k for k in range(len(labels)) if k != j)\n",
    "        plt.hist(\n",
    "            bins[j][:-1],\n",
    "            **plt_cfg.gen_kwargs(\n",
    "                type=\"hist\", index=j, bins=bins[j],\n",
    "                weights=info.sum(axis=sum_axes), label=lab))\n",
    "    plt_cfg.format_axis(xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()\n",
    "\n",
    "def plot_uncorr_templates(templates, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure(2, 2, figsize=(20, 12), title=\"Templates\")\n",
    "    for i, temp in enumerate(labels):\n",
    "        ax = axes[1-(i//2), i%2]\n",
    "        ax.set_title(f\"{temp} template\")\n",
    "        for j, lab in enumerate(labels):\n",
    "            lw = 3 + 2*(temp == lab)\n",
    "            ax.hist(\n",
    "                bins[j][:-1],\n",
    "                **plt_cfg.gen_kwargs(\n",
    "                    type=\"hist\", index=j, bins=bins[j],\n",
    "                    weights=templates[lab][i], label=lab, lw=lw))\n",
    "        plt_cfg.format_axis(ax, xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()\n",
    "\n",
    "def plot_uncorr_dist(info, bins, plt_cfg, labels = [\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "    fig, axes = plt_cfg.setup_figure()\n",
    "    for j, lab in enumerate(labels):\n",
    "        plt.hist(\n",
    "            bins[j][:-1],\n",
    "            **plt_cfg.gen_kwargs(\n",
    "                type=\"hist\", index=j, bins=bins[j],\n",
    "                weights=info[lab], label=lab))\n",
    "    plt_cfg.format_axis(xlabel=\"GNN score\", ylabel = \"Count\")\n",
    "    return plt_cfg.end_plot()\n",
    "\n",
    "def sqrt_func(x, a, b, c):\n",
    "    return a * np.sqrt(x-b) + c\n",
    "\n",
    "def plot_and_fit_range(x, x_lab, n_pulls, fits, errs=None, fit_sqrt=True, title=None):\n",
    "    # if fit_sqrt:\n",
    "    #     sqrt_params = []\n",
    "    #     for j in range(4):\n",
    "    #         sqrt_params.append(opt.curve_fit(\n",
    "    #             sqrt_func, x, fits[:, j, 0], p0=np.array([-1., 0., 0., 1.]),\n",
    "    #             bounds=(np.array([-100, 0, -10, 0]), np.array([100, 100, 10, 100])))[0])\n",
    "    if errs is not None:\n",
    "        fig, axes = plt_conf.setup_figure(2, 1, figsize=(10, 12.5))\n",
    "        if title is not None:\n",
    "            fig.suptitle(title)\n",
    "        for i, line in enumerate([\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "            # ax.set_title(f\"Weighting {lab}\")\n",
    "            axes[0].plot(x, fits[:, i, 0],\n",
    "                    **plt_conf.gen_kwargs(index=i, label=f\"{line}\", c=f\"C{i}\"))\n",
    "            axes[0].fill_between(x,\n",
    "                                 fits[:, i, 0]-fits[:, i, 1]/np.sqrt(n_pulls),\n",
    "                                 fits[:, i, 0]+fits[:, i, 1]/np.sqrt(n_pulls),\n",
    "                                 **plt_conf.gen_kwargs(index=i, fc=f\"C{i}\", alpha=0.2))\n",
    "            if fit_sqrt:\n",
    "                fit_params = opt.curve_fit(\n",
    "                    sqrt_func, x, fits[:, i, 0], p0=np.array([-0.01, 0., 0.]),\n",
    "                    bounds=(np.array([-100, -100, -10]), np.array([100, np.min(x), 10])),\n",
    "                    method=\"trf\", max_nfev=10000)[0]\n",
    "                axes[0].plot(x, sqrt_func(x, *fit_params),\n",
    "                             **plt_conf.gen_kwargs(\n",
    "                                 index=i, ls=\"--\", c=f\"C{i}\"))\n",
    "                        # label=f\"{line}:{sqrt_params[i][0]:.1e}sqrt(x-{sqrt_params[i][1]:.1f})+{sqrt_params[i][2]:.2f}\"))\n",
    "            axes[1].plot(x, errs[:, i, 0],\n",
    "                    **plt_conf.gen_kwargs(index=i, label=f\"{line}\"))\n",
    "        plt_conf.format_axis(axes[0], xlabel=x_lab, ylabel = \"Mean pull\")#, ylim=(-1, 1))\n",
    "        plt_conf.format_axis(axes[1], xlabel=x_lab, ylabel = \"Error from fit\")#, ylim=(-1, 1))\n",
    "    else:\n",
    "        fig, axes = plt_conf.setup_figure()\n",
    "        if title is not None:\n",
    "            fig.suptitle(title)\n",
    "        for i, line in enumerate([\"Abs.\", \"CEx.\", \"1 pi\", \"Multi.\"]):\n",
    "            # ax.set_title(f\"Weighting {lab}\")\n",
    "            plt.plot(x, fits[:, i, 0],\n",
    "                    **plt_conf.gen_kwargs(index=i, label=f\"{line}\"))\n",
    "            plt.fill_between(x,\n",
    "                             fits[:, i, 0]-fits[:, i, 1]/np.sqrt(n_pulls),\n",
    "                             fits[:, i, 0]+fits[:, i, 1]/np.sqrt(n_pulls),\n",
    "                             **plt_conf.gen_kwargs(index=i, fc=f\"C{i}\", alpha=0.2))\n",
    "            if fit_sqrt:\n",
    "                plt.plot(x, sqrt_func(x, *sqrt_params[i]),\n",
    "                         **plt_conf.gen_kwargs(\n",
    "                             index=i, ls=\"--\", c=f\"C{i}\"))\n",
    "        plt_conf.format_axis(xlabel=x_lab, ylabel = \"Mean pull\")#, ylim=(-1, 1))\n",
    "    plt_conf.end_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = np.concatenate([temp_pred, mc_data_pred], axis=0)\n",
    "all_truth = np.concatenate([temp_truth, mc_data_truth], axis=0)\n",
    "all_n_pfos = np.concatenate([temp_n_pfos, mc_data_n_pfos], axis=0)\n",
    "all_energies = np.concatenate([temp_energies, mc_data_energies], axis=0)\n",
    "all_true_energies = np.concatenate([temp_true_energies, mc_data_true_energies], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Fitter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi0-phys-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
